{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SNF_ci_vW_p"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZtCV6XYC4XP"
      },
      "outputs": [],
      "source": [
        "openai_api_key = ''\n",
        "model_name = 'gpt-4' # 'text-davinci-002'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot-vp9byu94w",
        "outputId": "6d7035d0-d830-47df-8839-6eec4ad6549f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: pybullet in /usr/local/lib/python3.10/dist-packages (3.2.6)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (67.7.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Thu Feb  1 19:03:22 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy scipy shapely astunparse pygments openai > /dev/null 2>&1\n",
        "!pip install imageio==2.4.1 imageio-ffmpeg pybullet moviepy\n",
        "!pip install openai==0.28\n",
        "\n",
        "import os\n",
        "import pybullet\n",
        "import pybullet_data\n",
        "import numpy as np\n",
        "import threading\n",
        "import copy\n",
        "import openai\n",
        "import cv2\n",
        "import imageio\n",
        "from google.colab.patches import cv2_imshow\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "\n",
        "# imports for LMPs\n",
        "import shapely\n",
        "import ast\n",
        "import astunparse\n",
        "from time import sleep\n",
        "from shapely.geometry import *\n",
        "from shapely.affinity import *\n",
        "from openai.error import RateLimitError, APIConnectionError\n",
        "from pygments import highlight\n",
        "from pygments.lexers import PythonLexer\n",
        "from pygments.formatters import TerminalFormatter\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Download PyBullet assets.\n",
        "if not os.path.exists('ur5e/ur5e.urdf'):\n",
        "  !gdown --id 1Cc_fDSBL6QiDvNT4dpfAEbhbALSVoWcc\n",
        "  !gdown --id 1yOMEm-Zp_DL3nItG9RozPeJAmeOldekX\n",
        "  !gdown --id 1GsqNLhEl9dd4Mc3BM0dX3MibOI1FVWNM\n",
        "  !unzip ur5e.zip\n",
        "  !unzip robotiq_2f_85.zip\n",
        "  !unzip bowl.zip\n",
        "\n",
        "!nvidia-smi  # Show useful GPU info."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPMS8UWXBym6"
      },
      "source": [
        "# Exceptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FQIJXNNWB00m"
      },
      "outputs": [],
      "source": [
        "class DetectionFailure(Exception):\n",
        "  def __init__(self, name, reason=''):\n",
        "    self.name = name\n",
        "    self.reason = reason\n",
        "\n",
        "\n",
        "class PickFailure(Exception):\n",
        "  def __init__(self, name, reason=''):\n",
        "    self.name = name\n",
        "    self.reason = reason\n",
        "\n",
        "\n",
        "class PlaceFailure(Exception):\n",
        "  def __init__(self, name, reason=''):\n",
        "    self.name = name\n",
        "    self.reason = reason\n",
        "\n",
        "\n",
        "class PushFailure(Exception):\n",
        "  def __init__(self, name, reason):\n",
        "    self.name = name\n",
        "    self.reason = reason"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbESO6mwDIEO"
      },
      "source": [
        "# LMP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WDEDCM4h7JLs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zeLPNzZu3sgA"
      },
      "outputs": [],
      "source": [
        "class LMP:\n",
        "\n",
        "    def __init__(self, name, cfg, lmp_fgen, fixed_vars, variable_vars):\n",
        "        self._name = name\n",
        "        self._cfg = cfg\n",
        "\n",
        "        self._base_prompt = self._cfg['prompt_text']\n",
        "\n",
        "        self._stop_tokens = list(self._cfg['stop'])\n",
        "\n",
        "        self._lmp_fgen = lmp_fgen\n",
        "\n",
        "        self._fixed_vars = fixed_vars\n",
        "        self._variable_vars = variable_vars\n",
        "        self.exec_hist = ''\n",
        "\n",
        "    def clear_exec_hist(self):\n",
        "        self.exec_hist = ''\n",
        "\n",
        "    def build_prompt(self, query, context=''):\n",
        "        if len(self._variable_vars) > 0:\n",
        "            variable_vars_imports_str = f\"from utils import {', '.join(self._variable_vars.keys())}\"\n",
        "        else:\n",
        "            variable_vars_imports_str = ''\n",
        "        prompt = self._base_prompt.replace('{variable_vars_imports}', variable_vars_imports_str)\n",
        "\n",
        "        if self._cfg['maintain_session']:\n",
        "            prompt += f'\\n{self.exec_hist}'\n",
        "\n",
        "        if context != '':\n",
        "            prompt += f'\\n{context}'\n",
        "\n",
        "        use_query = f'{self._cfg[\"query_prefix\"]}{query}{self._cfg[\"query_suffix\"]}'\n",
        "        prompt += f'\\n{use_query}'\n",
        "\n",
        "        return prompt, use_query\n",
        "\n",
        "    def _cached_api_call(self, **kwargs):\n",
        "      # check whether completion endpoint or chat endpoint is used\n",
        "      # if kwargs['model'] != 'gpt-3.5-turbo-instruct' and \\\n",
        "      #   any([chat_model in kwargs['model'] for chat_model in ['gpt-3.5', 'gpt-4']]):\n",
        "      if True:\n",
        "        # add special prompt for chat endpoint\n",
        "        user1 = kwargs.pop('prompt')\n",
        "        new_query = '# Query:' + user1.split('# Query:')[-1]\n",
        "        user1 = ''.join(user1.split('# Query:')[:-1]).strip()\n",
        "        user1 = f\"I would like you to help me write Python code to control a robot arm operating in a tabletop environment. Please complete the code every time when I give you new query. Pay attention to appeared patterns in the given context code. Be thorough and thoughtful in your code. Do not include any import statement. Do not repeat my question. Do not provide any text explanation (comment in code is okay). I will first give you the context of the code below:\\n\\n```\\n{user1}\\n```\\n\\nNote that x is back to front, y is left to right, and z is bottom to up.\"\n",
        "        assistant1 = f'Got it. I will complete what you give me next.'\n",
        "        user2 = new_query\n",
        "        # print(user2)\n",
        "        # handle given context (this was written originally for completion endpoint)\n",
        "        if user1.split('\\n')[-4].startswith('objects = ['):\n",
        "          obj_context = user1.split('\\n')[-4]\n",
        "          # remove obj_context from user1\n",
        "          user1 = '\\n'.join(user1.split('\\n')[:-4]) + '\\n' + '\\n'.join(user1.split('\\n')[-3:])\n",
        "          # add obj_context to user2\n",
        "          user2 = obj_context.strip() + '\\n' + user2\n",
        "        messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that pays attention to the user's instructions and writes good python code for operating a robot arm in a tabletop environment.\"},\n",
        "                {\"role\": \"user\", \"content\": user1},\n",
        "                {\"role\": \"assistant\", \"content\": assistant1},\n",
        "                {\"role\": \"user\", \"content\": user2},\n",
        "            ]\n",
        "        kwargs['messages'] = messages\n",
        "        # print(kwargs)\n",
        "        # if kwargs in self._cache:\n",
        "        if False:\n",
        "          print('(using cache)', end=' ')\n",
        "          return self._cache[kwargs]\n",
        "        else:\n",
        "          ret = openai.ChatCompletion.create(**kwargs)['choices'][0]['message']['content']\n",
        "          # print('Generated plan:')\n",
        "          # print(ret)\n",
        "          # post processing\n",
        "          ret = ret.replace('```', '').replace('python', '').strip()\n",
        "          # self._cache[kwargs] = ret\n",
        "          return ret\n",
        "      else:\n",
        "        if kwargs in self._cache:\n",
        "          print('(using cache)', end=' ')\n",
        "          return self._cache[kwargs]\n",
        "        else:\n",
        "          ret = openai.Completion.create(**kwargs)['choices'][0]['text'].strip()\n",
        "          self._cache[kwargs] = ret\n",
        "          return ret\n",
        "\n",
        "    def __call__(self, query, context='', **kwargs):\n",
        "        prompt, use_query = self.build_prompt(query, context=context)\n",
        "        while True:\n",
        "            try:\n",
        "                code_str = self._cached_api_call(\n",
        "                    prompt=prompt,\n",
        "                    stop=self._stop_tokens,\n",
        "                    temperature=self._cfg['temperature'],\n",
        "                    model=self._cfg['engine'],\n",
        "                    max_tokens=self._cfg['max_tokens']\n",
        "                )\n",
        "                break\n",
        "            except (RateLimitError, APIConnectionError) as e:\n",
        "              print(f'OpenAI API got err {e}')\n",
        "              print('Retrying after 10s.')\n",
        "              sleep(10)\n",
        "\n",
        "        if self._cfg['include_context'] and context != '':\n",
        "            to_exec = f'{context}\\n{code_str}'\n",
        "            to_log = f'{context}\\n{use_query}\\n{code_str}'\n",
        "        else:\n",
        "            to_exec = code_str\n",
        "            to_log = f'{use_query}\\n{to_exec}'\n",
        "\n",
        "        to_log_pretty = highlight(to_log, PythonLexer(), TerminalFormatter())\n",
        "        print(f'LMP {self._name} exec:\\n\\n{to_log_pretty}\\n')\n",
        "\n",
        "        new_fs = self._lmp_fgen.create_new_fs_from_code(code_str)\n",
        "        self._variable_vars.update(new_fs)\n",
        "\n",
        "        gvars = merge_dicts([self._fixed_vars, self._variable_vars])\n",
        "        lvars = kwargs\n",
        "\n",
        "        if not self._cfg['debug_mode']:\n",
        "            exec_safe(to_exec, gvars, lvars)\n",
        "\n",
        "        self.exec_hist += f'\\n{to_exec}'\n",
        "\n",
        "        if self._cfg['maintain_session']:\n",
        "            self._variable_vars.update(lvars)\n",
        "\n",
        "        if self._cfg['has_return']:\n",
        "          print('lvars: ', lvars)\n",
        "          print('self._cfg: ', self._cfg)\n",
        "          # return lvars[self._cfg['return_val_name']]\n",
        "\n",
        "\n",
        "class LMPFGen:\n",
        "\n",
        "    def __init__(self, cfg, fixed_vars, variable_vars):\n",
        "        self._cfg = cfg\n",
        "\n",
        "        self._stop_tokens = list(self._cfg['stop'])\n",
        "        self._fixed_vars = fixed_vars\n",
        "        self._variable_vars = variable_vars\n",
        "\n",
        "        self._base_prompt = self._cfg['prompt_text']\n",
        "\n",
        "    def create_f_from_sig(self, f_name, f_sig, other_vars=None, fix_bugs=False, return_src=False):\n",
        "        print(f'Creating function: {f_sig}')\n",
        "\n",
        "        use_query = f'{self._cfg[\"query_prefix\"]}{f_sig}{self._cfg[\"query_suffix\"]}'\n",
        "        prompt = f'{self._base_prompt}\\n{use_query}'\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                f_src = openai.Completion.create(\n",
        "                    prompt=prompt,\n",
        "                    stop=self._stop_tokens,\n",
        "                    temperature=self._cfg['temperature'],\n",
        "                    engine=self._cfg['engine'],\n",
        "                    max_tokens=self._cfg['max_tokens']\n",
        "                )['choices'][0]['text'].strip()\n",
        "                break\n",
        "            except (RateLimitError, APIConnectionError) as e:\n",
        "                print(f'OpenAI API got err {e}')\n",
        "                print('Retrying after 10s.')\n",
        "                sleep(10)\n",
        "\n",
        "        if fix_bugs:\n",
        "            f_src = openai.Edit.create(\n",
        "                model='code-davinci-edit-001',\n",
        "                input='# ' + f_src,\n",
        "                temperature=0,\n",
        "                instruction='Fix the bug if there is one. Improve readability. Keep same inputs and outputs. Only small changes. No comments.',\n",
        "            )['choices'][0]['text'].strip()\n",
        "\n",
        "        if other_vars is None:\n",
        "            other_vars = {}\n",
        "        gvars = merge_dicts([self._fixed_vars, self._variable_vars, other_vars])\n",
        "        lvars = {}\n",
        "\n",
        "        exec_safe(f_src, gvars, lvars)\n",
        "\n",
        "        f = lvars[f_name]\n",
        "\n",
        "        to_print = highlight(f'{use_query}\\n{f_src}', PythonLexer(), TerminalFormatter())\n",
        "        print(f'LMP FGEN created:\\n\\n{to_print}\\n')\n",
        "\n",
        "        if return_src:\n",
        "            return f, f_src\n",
        "        return f\n",
        "\n",
        "    def create_new_fs_from_code(self, code_str, other_vars=None, fix_bugs=False, return_src=False):\n",
        "        fs, f_assigns = {}, {}\n",
        "        f_parser = FunctionParser(fs, f_assigns)\n",
        "        f_parser.visit(ast.parse(code_str))\n",
        "        for f_name, f_assign in f_assigns.items():\n",
        "            if f_name in fs:\n",
        "                fs[f_name] = f_assign\n",
        "\n",
        "        if other_vars is None:\n",
        "            other_vars = {}\n",
        "\n",
        "        new_fs = {}\n",
        "        srcs = {}\n",
        "        for f_name, f_sig in fs.items():\n",
        "            all_vars = merge_dicts([self._fixed_vars, self._variable_vars, new_fs, other_vars])\n",
        "            if not var_exists(f_name, all_vars):\n",
        "                f, f_src = self.create_f_from_sig(f_name, f_sig, new_fs, fix_bugs=fix_bugs, return_src=True)\n",
        "\n",
        "                # recursively define child_fs in the function body if needed\n",
        "                f_def_body = astunparse.unparse(ast.parse(f_src).body[0].body)\n",
        "                child_fs, child_f_srcs = self.create_new_fs_from_code(\n",
        "                    f_def_body, other_vars=all_vars, fix_bugs=fix_bugs, return_src=True\n",
        "                )\n",
        "\n",
        "                if len(child_fs) > 0:\n",
        "                    new_fs.update(child_fs)\n",
        "                    srcs.update(child_f_srcs)\n",
        "\n",
        "                    # redefine parent f so newly created child_fs are in scope\n",
        "                    gvars = merge_dicts([self._fixed_vars, self._variable_vars, new_fs, other_vars])\n",
        "                    lvars = {}\n",
        "\n",
        "                    exec_safe(f_src, gvars, lvars)\n",
        "\n",
        "                    f = lvars[f_name]\n",
        "\n",
        "                new_fs[f_name], srcs[f_name] = f, f_src\n",
        "\n",
        "        if return_src:\n",
        "            return new_fs, srcs\n",
        "        return new_fs\n",
        "\n",
        "\n",
        "class FunctionParser(ast.NodeTransformer):\n",
        "\n",
        "    def __init__(self, fs, f_assigns):\n",
        "      super().__init__()\n",
        "      self._fs = fs\n",
        "      self._f_assigns = f_assigns\n",
        "\n",
        "    def visit_Call(self, node):\n",
        "        self.generic_visit(node)\n",
        "        if isinstance(node.func, ast.Name):\n",
        "            f_sig = astunparse.unparse(node).strip()\n",
        "            f_name = astunparse.unparse(node.func).strip()\n",
        "            self._fs[f_name] = f_sig\n",
        "        return node\n",
        "\n",
        "    def visit_Assign(self, node):\n",
        "        self.generic_visit(node)\n",
        "        if isinstance(node.value, ast.Call):\n",
        "            assign_str = astunparse.unparse(node).strip()\n",
        "            f_name = astunparse.unparse(node.value.func).strip()\n",
        "            self._f_assigns[f_name] = assign_str\n",
        "        return node\n",
        "\n",
        "\n",
        "def var_exists(name, all_vars):\n",
        "    try:\n",
        "        eval(name, all_vars)\n",
        "    except:\n",
        "        exists = False\n",
        "    else:\n",
        "        exists = True\n",
        "    return exists\n",
        "\n",
        "\n",
        "def merge_dicts(dicts):\n",
        "    return {\n",
        "        k : v\n",
        "        for d in dicts\n",
        "        for k, v in d.items()\n",
        "    }\n",
        "\n",
        "\n",
        "def exec_safe(code_str, gvars=None, lvars=None):\n",
        "    banned_phrases = ['import', '__']\n",
        "    for phrase in banned_phrases:\n",
        "        assert phrase not in code_str\n",
        "\n",
        "    if gvars is None:\n",
        "        gvars = {}\n",
        "    if lvars is None:\n",
        "        lvars = {}\n",
        "    empty_fn = lambda *args, **kwargs: None\n",
        "    custom_gvars = merge_dicts([\n",
        "        gvars,\n",
        "        {'exec': empty_fn, 'eval': empty_fn}\n",
        "    ])\n",
        "    exec(code_str, custom_gvars, lvars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ITyMRSk2jJUu"
      },
      "outputs": [],
      "source": [
        "def setup_LMP(env, cfg_tabletop):\n",
        "  # LMP env wrapper\n",
        "  cfg_tabletop = copy.deepcopy(cfg_tabletop)\n",
        "  cfg_tabletop['env'] = dict()\n",
        "  cfg_tabletop['env']['init_objs'] = list(env.obj_name_to_id.keys())\n",
        "  cfg_tabletop['env']['coords'] = lmp_tabletop_coords\n",
        "#   wrapper = LMP_wrapper(env, cfg_tabletop)\n",
        "  LMP_env = LMP_interface(env, cfg_tabletop)\n",
        "  # creating APIs that the LMPs can interact with\n",
        "  fixed_vars = {\n",
        "      'np': np\n",
        "  }\n",
        "  fixed_vars.update({\n",
        "      name: eval(name)\n",
        "      for name in shapely.geometry.__all__ + shapely.affinity.__all__\n",
        "  })\n",
        "  variable_vars = {\n",
        "      k: getattr(LMP_env, k)\n",
        "      for k in [\n",
        "          'get_bbox', 'get_obj_pos', 'get_color', 'is_obj_visible', 'denormalize_xy',\n",
        "          'put_first_on_second', 'get_obj_names',\n",
        "          'get_corner_name', 'get_side_name',\n",
        "      ]\n",
        "  }\n",
        "  variable_vars['say'] = lambda msg: print(f'robot says: {msg}')\n",
        "\n",
        "  # creating the function-generating LMP\n",
        "  lmp_fgen = LMPFGen(cfg_tabletop['lmps']['fgen'], fixed_vars, variable_vars)\n",
        "\n",
        "  # creating other low-level LMPs\n",
        "  variable_vars.update({\n",
        "      k: LMP(k, cfg_tabletop['lmps'][k], lmp_fgen, fixed_vars, variable_vars)\n",
        "      for k in ['parse_obj_name', 'parse_position', 'parse_question', 'transform_shape_pts']\n",
        "  })\n",
        "\n",
        "  # creating the LMP that deals w/ high-level language commands\n",
        "  lmp_tabletop_ui = LMP(\n",
        "      'table_ui', cfg_tabletop['lmps']['table_ui'], lmp_fgen, fixed_vars, variable_vars\n",
        "  )\n",
        "\n",
        "  return lmp_tabletop_ui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWu8o61yDKDP"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RC2oGB8wDJMX"
      },
      "outputs": [],
      "source": [
        "# # Global constants: pick and place objects, colors, workspace bounds\n",
        "COLORS = {\n",
        "    'blue':   (78/255,  121/255, 167/255, 255/255),\n",
        "    'red':    (255/255,  87/255,  89/255, 255/255),\n",
        "    'green':  (89/255,  169/255,  79/255, 255/255),\n",
        "    'orange': (242/255, 142/255,  43/255, 255/255),\n",
        "    'yellow': (237/255, 201/255,  72/255, 255/255),\n",
        "    'purple': (176/255, 122/255, 161/255, 255/255),\n",
        "    'pink':   (255/255, 157/255, 167/255, 255/255),\n",
        "    'cyan':   (118/255, 183/255, 178/255, 255/255),\n",
        "    'brown':  (156/255, 117/255,  95/255, 255/255),\n",
        "    'gray':   (186/255, 176/255, 172/255, 255/255),\n",
        "}\n",
        "\n",
        "CORNER_POS = {\n",
        "  'top left corner':     (-0.3 + 0.05, -0.2 - 0.05, 0),\n",
        "  'top side':            (0,           -0.2 - 0.05, 0),\n",
        "  'top right corner':    (0.3 - 0.05,  -0.2 - 0.05, 0),\n",
        "  'left side':           (-0.3 + 0.05, -0.5,        0),\n",
        "  'middle':              (0,           -0.5,        0),\n",
        "  'right side':          (0.3 - 0.05,  -0.5,        0),\n",
        "  'bottom left corner':  (-0.3 + 0.05, -0.8 + 0.05, 0),\n",
        "  'bottom side':         (0,           -0.8 + 0.05, 0),\n",
        "  'bottom right corner': (0.3 - 0.05,  -0.8 + 0.05, 0),\n",
        "}\n",
        "\n",
        "ALL_BLOCKS = ['blue block', 'red block', 'green block', 'orange block', 'yellow block', 'purple block', 'pink block', 'cyan block', 'brown block', 'gray block']\n",
        "ALL_BOWLS = ['blue bowl', 'red bowl', 'green bowl', 'orange bowl', 'yellow bowl', 'purple bowl', 'pink bowl', 'cyan bowl', 'brown bowl', 'gray bowl']\n",
        "\n",
        "PIXEL_SIZE = 0.00267857\n",
        "BOUNDS = np.float32([[-0.3, 0.3], [-0.8, -0.2], [0, 0.15]])  # X Y Z\n",
        "\n",
        "lmp_tabletop_coords = {\n",
        "        'top_left':     (-0.3 + 0.05, -0.2 - 0.05),\n",
        "        'top_side':     (0,           -0.2 - 0.05),\n",
        "        'top_right':    (0.3 - 0.05,  -0.2 - 0.05),\n",
        "        'left_side':    (-0.3 + 0.05, -0.5,      ),\n",
        "        'middle':       (0,           -0.5,      ),\n",
        "        'right_side':   (0.3 - 0.05,  -0.5,      ),\n",
        "        'bottom_left':  (-0.3 + 0.05, -0.8 + 0.05),\n",
        "        'bottom_side':  (0,           -0.8 + 0.05),\n",
        "        'bottom_right': (0.3 - 0.05,  -0.8 + 0.05),\n",
        "        'table_z':       0.0,\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhJlrXoPDQej"
      },
      "source": [
        "# Gripper and Environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qFR1uzKfDNoo"
      },
      "outputs": [],
      "source": [
        "# Gripper (Robotiq 2F85) code\n",
        "\n",
        "class Robotiq2F85:\n",
        "  \"\"\"Gripper handling for Robotiq 2F85.\"\"\"\n",
        "\n",
        "  def __init__(self, robot, tool):\n",
        "    self.robot = robot\n",
        "    self.tool = tool\n",
        "    pos = [0.1339999999999999, -0.49199999999872496, 0.5]\n",
        "    rot = pybullet.getQuaternionFromEuler([np.pi, 0, np.pi])\n",
        "    urdf = 'robotiq_2f_85/robotiq_2f_85.urdf'\n",
        "    self.body = pybullet.loadURDF(urdf, pos, rot)\n",
        "    self.n_joints = pybullet.getNumJoints(self.body)\n",
        "    self.activated = False\n",
        "\n",
        "    # Connect gripper base to robot tool.\n",
        "    pybullet.createConstraint(self.robot, tool, self.body, 0, jointType=pybullet.JOINT_FIXED, jointAxis=[0, 0, 0], parentFramePosition=[0, 0, 0], childFramePosition=[0, 0, -0.07], childFrameOrientation=pybullet.getQuaternionFromEuler([0, 0, np.pi / 2]))\n",
        "\n",
        "    # Set friction coefficients for gripper fingers.\n",
        "    for i in range(pybullet.getNumJoints(self.body)):\n",
        "      pybullet.changeDynamics(self.body, i, lateralFriction=10.0, spinningFriction=1.0, rollingFriction=1.0, frictionAnchor=True)\n",
        "\n",
        "    # Start thread to handle additional gripper constraints.\n",
        "    self.motor_joint = 1\n",
        "    self.constraints_thread = threading.Thread(target=self.step)\n",
        "    self.constraints_thread.daemon = True\n",
        "    self.constraints_thread.start()\n",
        "\n",
        "  # Control joint positions by enforcing hard contraints on gripper behavior.\n",
        "  # Set one joint as the open/close motor joint (other joints should mimic).\n",
        "  def step(self):\n",
        "    while True:\n",
        "      try:\n",
        "        currj = [pybullet.getJointState(self.body, i)[0] for i in range(self.n_joints)]\n",
        "        indj = [6, 3, 8, 5, 10]\n",
        "        targj = [currj[1], -currj[1], -currj[1], currj[1], currj[1]]\n",
        "        pybullet.setJointMotorControlArray(self.body, indj, pybullet.POSITION_CONTROL, targj, positionGains=np.ones(5))\n",
        "      except:\n",
        "        return\n",
        "      sleep(0.001)\n",
        "\n",
        "  # Close gripper fingers.\n",
        "  def activate(self):\n",
        "    pybullet.setJointMotorControl2(self.body, self.motor_joint, pybullet.VELOCITY_CONTROL, targetVelocity=1, force=10)\n",
        "    self.activated = True\n",
        "\n",
        "  # Open gripper fingers.\n",
        "  def release(self):\n",
        "    pybullet.setJointMotorControl2(self.body, self.motor_joint, pybullet.VELOCITY_CONTROL, targetVelocity=-1, force=10)\n",
        "    self.activated = False\n",
        "\n",
        "  # If activated and object in gripper: check object contact.\n",
        "  # If activated and nothing in gripper: check gripper contact.\n",
        "  # If released: check proximity to surface (disabled).\n",
        "  def detect_contact(self):\n",
        "    obj, _, ray_frac = self.check_proximity()\n",
        "    if self.activated:\n",
        "      empty = self.grasp_width() < 0.01\n",
        "      cbody = self.body if empty else obj\n",
        "      if obj == self.body or obj == 0:\n",
        "        return False\n",
        "      return self.external_contact(cbody)\n",
        "  #   else:\n",
        "  #     return ray_frac < 0.14 or self.external_contact()\n",
        "\n",
        "  # Return if body is in contact with something other than gripper\n",
        "  def external_contact(self, body=None):\n",
        "    if body is None:\n",
        "      body = self.body\n",
        "    pts = pybullet.getContactPoints(bodyA=body)\n",
        "    pts = [pt for pt in pts if pt[2] != self.body]\n",
        "    return len(pts) > 0  # pylint: disable=g-explicit-length-test\n",
        "\n",
        "  def check_grasp(self):\n",
        "    while self.moving():\n",
        "      sleep(0.001)\n",
        "    success = self.grasp_width() > 0.01\n",
        "    return success\n",
        "\n",
        "  def grasp_width(self):\n",
        "    lpad = np.array(pybullet.getLinkState(self.body, 4)[0])\n",
        "    rpad = np.array(pybullet.getLinkState(self.body, 9)[0])\n",
        "    dist = np.linalg.norm(lpad - rpad) - 0.047813\n",
        "    return dist\n",
        "\n",
        "  def check_proximity(self):\n",
        "    ee_pos = np.array(pybullet.getLinkState(self.robot, self.tool)[0])\n",
        "    tool_pos = np.array(pybullet.getLinkState(self.body, 0)[0])\n",
        "    vec = (tool_pos - ee_pos) / np.linalg.norm((tool_pos - ee_pos))\n",
        "    ee_targ = ee_pos + vec\n",
        "    ray_data = pybullet.rayTest(ee_pos, ee_targ)[0]\n",
        "    obj, link, ray_frac = ray_data[0], ray_data[1], ray_data[2]\n",
        "    return obj, link, ray_frac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VramKK4nDST9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Gym-style environment code\n",
        "\n",
        "class PickPlaceEnv():\n",
        "\n",
        "  def __init__(self, render=False, high_res=False, high_frame_rate=False, test=False):\n",
        "    self.dt = 1/480\n",
        "    self.sim_step = 0\n",
        "\n",
        "    # Configure and start PyBullet.\n",
        "    # python3 -m pybullet_utils.runServer\n",
        "    # pybullet.connect(pybullet.SHARED_MEMORY)  # pybullet.GUI for local GUI.\n",
        "\n",
        "    if test:\n",
        "      pybullet.connect(pybullet.GUI)\n",
        "    else:\n",
        "      pybullet.connect(pybullet.DIRECT)  # pybullet.GUI for local GUI.\n",
        "\n",
        "\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_GUI, 0)\n",
        "    pybullet.setPhysicsEngineParameter(enableFileCaching=0)\n",
        "    assets_path = os.path.dirname(os.path.abspath(\"\"))\n",
        "    pybullet.setAdditionalSearchPath(assets_path)\n",
        "    pybullet.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "    pybullet.setTimeStep(self.dt)\n",
        "\n",
        "    self.home_joints = (np.pi / 2, -np.pi / 2, np.pi / 2, -np.pi / 2, 3 * np.pi / 2, 0)  # Joint angles: (J0, J1, J2, J3, J4, J5).\n",
        "    self.home_ee_euler = (np.pi, 0, np.pi)  # (RX, RY, RZ) rotation in Euler angles.\n",
        "    self.ee_link_id = 9  # Link ID of UR5 end effector.\n",
        "    self.tip_link_id = 10  # Link ID of gripper finger tips.\n",
        "    self.gripper = None\n",
        "\n",
        "    self.render = render\n",
        "    self.high_res = high_res\n",
        "    self.high_frame_rate = high_frame_rate\n",
        "\n",
        "  def reset(self, object_list):\n",
        "    pybullet.resetSimulation(pybullet.RESET_USE_DEFORMABLE_WORLD)\n",
        "    pybullet.setGravity(0, 0, -9.8)\n",
        "    self.cache_video = []\n",
        "\n",
        "    # Temporarily disable rendering to load URDFs faster.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_RENDERING, 0)\n",
        "\n",
        "    # Add robot.\n",
        "    pybullet.loadURDF(\"plane.urdf\", [0, 0, -0.001])\n",
        "    self.robot_id = pybullet.loadURDF(\"ur5e/ur5e.urdf\", [0, 0, 0], flags=pybullet.URDF_USE_MATERIAL_COLORS_FROM_MTL)\n",
        "    self.ghost_id = pybullet.loadURDF(\"ur5e/ur5e.urdf\", [0, 0, -10])  # For forward kinematics.\n",
        "    self.joint_ids = [pybullet.getJointInfo(self.robot_id, i) for i in range(pybullet.getNumJoints(self.robot_id))]\n",
        "    self.joint_ids = [j[0] for j in self.joint_ids if j[2] == pybullet.JOINT_REVOLUTE]\n",
        "\n",
        "    # Move robot to home configuration.\n",
        "    for i in range(len(self.joint_ids)):\n",
        "      pybullet.resetJointState(self.robot_id, self.joint_ids[i], self.home_joints[i])\n",
        "\n",
        "    # Add gripper.\n",
        "    if self.gripper is not None:\n",
        "      while self.gripper.constraints_thread.is_alive():\n",
        "        self.constraints_thread_active = False\n",
        "    self.gripper = Robotiq2F85(self.robot_id, self.ee_link_id)\n",
        "    self.gripper.release()\n",
        "\n",
        "    # Add workspace.\n",
        "    plane_shape = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[0.3, 0.3, 0.001])\n",
        "    plane_visual = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[0.3, 0.3, 0.001])\n",
        "    plane_id = pybullet.createMultiBody(0, plane_shape, plane_visual, basePosition=[0, -0.5, 0])\n",
        "    pybullet.changeVisualShape(plane_id, -1, rgbaColor=[0.2, 0.2, 0.2, 1.0])\n",
        "\n",
        "    # Load objects according to config.\n",
        "    self.object_list = object_list\n",
        "    self.obj_name_to_id = {}\n",
        "    obj_xyz = np.zeros((0, 3))\n",
        "    for obj_name in object_list:\n",
        "      if ('block' in obj_name) or ('bowl' in obj_name):\n",
        "\n",
        "        # Get random position 15cm+ from other objects.\n",
        "        while True:\n",
        "          rand_x = np.random.uniform(BOUNDS[0, 0] + 0.1, BOUNDS[0, 1] - 0.1)\n",
        "          rand_y = np.random.uniform(BOUNDS[1, 0] + 0.1, BOUNDS[1, 1] - 0.1)\n",
        "          rand_xyz = np.float32([rand_x, rand_y, 0.03]).reshape(1, 3)\n",
        "          if len(obj_xyz) == 0:\n",
        "            obj_xyz = np.concatenate((obj_xyz, rand_xyz), axis=0)\n",
        "            break\n",
        "          else:\n",
        "            nn_dist = np.min(np.linalg.norm(obj_xyz - rand_xyz, axis=1)).squeeze()\n",
        "            if nn_dist > 0.15:\n",
        "              obj_xyz = np.concatenate((obj_xyz, rand_xyz), axis=0)\n",
        "              break\n",
        "\n",
        "        object_color = COLORS[obj_name.split(' ')[0]]\n",
        "        object_type = obj_name.split(' ')[1]\n",
        "        object_position = rand_xyz.squeeze()\n",
        "        if object_type == 'block':\n",
        "          object_shape = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02])\n",
        "          object_visual = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02])\n",
        "          object_id = pybullet.createMultiBody(0.01, object_shape, object_visual, basePosition=object_position)\n",
        "        elif object_type == 'bowl':\n",
        "          object_position[2] = 0\n",
        "          object_id = pybullet.loadURDF(\"bowl/bowl.urdf\", object_position, useFixedBase=1)\n",
        "        pybullet.changeVisualShape(object_id, -1, rgbaColor=object_color)\n",
        "        self.obj_name_to_id[obj_name] = object_id\n",
        "\n",
        "\n",
        "    # Re-enable rendering.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_RENDERING, 1)\n",
        "\n",
        "    for _ in range(200):\n",
        "      pybullet.stepSimulation()\n",
        "\n",
        "    # record object positions at reset\n",
        "    self.init_pos = {name: self.get_obj_pos(name) for name in object_list}\n",
        "\n",
        "    return self.get_observation()\n",
        "\n",
        "  def servoj(self, joints):\n",
        "    \"\"\"Move to target joint positions with position control.\"\"\"\n",
        "    pybullet.setJointMotorControlArray(\n",
        "      bodyIndex=self.robot_id,\n",
        "      jointIndices=self.joint_ids,\n",
        "      controlMode=pybullet.POSITION_CONTROL,\n",
        "      targetPositions=joints,\n",
        "      positionGains=[0.01]*6)\n",
        "\n",
        "  def movep(self, position):\n",
        "    \"\"\"Move to target end effector position.\"\"\"\n",
        "    joints = pybullet.calculateInverseKinematics(\n",
        "        bodyUniqueId=self.robot_id,\n",
        "        endEffectorLinkIndex=self.tip_link_id,\n",
        "        targetPosition=position,\n",
        "        targetOrientation=pybullet.getQuaternionFromEuler(self.home_ee_euler),\n",
        "        maxNumIterations=100)\n",
        "    self.servoj(joints)\n",
        "\n",
        "  def get_ee_pos(self):\n",
        "    ee_xyz = np.float32(pybullet.getLinkState(self.robot_id, self.tip_link_id)[0])\n",
        "    return ee_xyz\n",
        "\n",
        "  def step(self, action=None):\n",
        "    \"\"\"Do pick and place motion primitive.\"\"\"\n",
        "    pick_pos, place_pos = action['pick'].copy(), action['place'].copy()\n",
        "\n",
        "    # Set fixed primitive z-heights.\n",
        "    hover_xyz = np.float32([pick_pos[0], pick_pos[1], 0.2])\n",
        "    if pick_pos.shape[-1] == 2:\n",
        "      pick_xyz = np.append(pick_pos, 0.025)\n",
        "    else:\n",
        "      pick_xyz = pick_pos\n",
        "      pick_xyz[2] = 0.025\n",
        "    if place_pos.shape[-1] == 2:\n",
        "      place_xyz = np.append(place_pos, 0.15)\n",
        "    else:\n",
        "      place_xyz = place_pos\n",
        "      place_xyz[2] = 0.15\n",
        "\n",
        "    # Move to object.\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "    while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(hover_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    while np.linalg.norm(pick_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(pick_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    # Pick up object.\n",
        "    self.gripper.activate()\n",
        "    for _ in range(240):\n",
        "      self.step_sim_and_render()\n",
        "    while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(hover_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    for _ in range(50):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    # Move to place location.\n",
        "    while np.linalg.norm(place_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(place_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    # Place down object.\n",
        "    while (not self.gripper.detect_contact()) and (place_xyz[2] > 0.03):\n",
        "      place_xyz[2] -= 0.001\n",
        "      self.movep(place_xyz)\n",
        "      for _ in range(3):\n",
        "        self.step_sim_and_render()\n",
        "    self.gripper.release()\n",
        "    for _ in range(240):\n",
        "      self.step_sim_and_render()\n",
        "    place_xyz[2] = 0.2\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "    while np.linalg.norm(place_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(place_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "    place_xyz = np.float32([0, -0.5, 0.2])\n",
        "    while np.linalg.norm(place_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(place_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    observation = self.get_observation()\n",
        "    reward = self.get_reward()\n",
        "    done = False\n",
        "    info = {}\n",
        "    return observation, reward, done, info\n",
        "\n",
        "  def set_alpha_transparency(self, alpha: float) -> None:\n",
        "    for id in range(20):\n",
        "      visual_shape_data = pybullet.getVisualShapeData(id)\n",
        "      for i in range(len(visual_shape_data)):\n",
        "        object_id, link_index, _, _, _, _, _, rgba_color = visual_shape_data[i]\n",
        "        rgba_color = list(rgba_color[0:3]) +  [alpha]\n",
        "        pybullet.changeVisualShape(\n",
        "            self.robot_id, linkIndex=i, rgbaColor=rgba_color)\n",
        "        pybullet.changeVisualShape(\n",
        "            self.gripper.body, linkIndex=i, rgbaColor=rgba_color)\n",
        "\n",
        "  def step_sim_and_render(self):\n",
        "    pybullet.stepSimulation()\n",
        "    self.sim_step += 1\n",
        "\n",
        "    interval = 40 if self.high_frame_rate else 60\n",
        "    # Render current image at 8 FPS.\n",
        "    if self.sim_step % interval == 0 and self.render:\n",
        "      self.cache_video.append(self.get_camera_image())\n",
        "\n",
        "  def get_camera_image(self):\n",
        "    if not self.high_res:\n",
        "      image_size = (240, 240)\n",
        "      intrinsics = (120., 0, 120., 0, 120., 120., 0, 0, 1)\n",
        "    else:\n",
        "      image_size=(360, 360)\n",
        "      intrinsics=(180., 0, 180., 0, 180., 180., 0, 0, 1)\n",
        "    color, _, _, _, _ = self.render_image(image_size, intrinsics)\n",
        "    return color\n",
        "\n",
        "  def get_reward(self):\n",
        "    return None\n",
        "\n",
        "  def get_observation(self):\n",
        "    observation = {}\n",
        "\n",
        "    # Render current image.\n",
        "    color, depth, position, orientation, intrinsics = self.render_image()\n",
        "\n",
        "    # Get heightmaps and colormaps.\n",
        "    points = self.get_pointcloud(depth, intrinsics)\n",
        "    position = np.float32(position).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotation = np.float32(rotation).reshape(3, 3)\n",
        "    transform = np.eye(4)\n",
        "    transform[:3, :] = np.hstack((rotation, position))\n",
        "    points = self.transform_pointcloud(points, transform)\n",
        "    heightmap, colormap, xyzmap = self.get_heightmap(points, color, BOUNDS, PIXEL_SIZE)\n",
        "\n",
        "    observation[\"image\"] = colormap\n",
        "    observation[\"xyzmap\"] = xyzmap\n",
        "\n",
        "    return observation\n",
        "\n",
        "  def get_seg_image(self, image_size=(720, 720), intrinsics=(360., 0, 360., 0, 360., 360., 0, 0, 1)):\n",
        "    # Camera parameters.\n",
        "    position = (0, -0.85, 0.4)\n",
        "    orientation = (np.pi / 4 + np.pi / 48, np.pi, np.pi)\n",
        "    orientation = pybullet.getQuaternionFromEuler(orientation)\n",
        "    zrange = (0.01, 10.)\n",
        "    noise=True\n",
        "\n",
        "    # OpenGL camera settings.\n",
        "    lookdir = np.float32([0, 0, 1]).reshape(3, 1)\n",
        "    updir = np.float32([0, -1, 0]).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotm = np.float32(rotation).reshape(3, 3)\n",
        "    lookdir = (rotm @ lookdir).reshape(-1)\n",
        "    updir = (rotm @ updir).reshape(-1)\n",
        "    lookat = position + lookdir\n",
        "    focal_len = intrinsics[0]\n",
        "    znear, zfar = (0.01, 10.)\n",
        "    viewm = pybullet.computeViewMatrix(position, lookat, updir)\n",
        "    fovh = (image_size[0] / 2) / focal_len\n",
        "    fovh = 180 * np.arctan(fovh) * 2 / np.pi\n",
        "\n",
        "    # Notes: 1) FOV is vertical FOV 2) aspect must be float\n",
        "    aspect_ratio = image_size[1] / image_size[0]\n",
        "    projm = pybullet.computeProjectionMatrixFOV(fovh, aspect_ratio, znear, zfar)\n",
        "\n",
        "    # Render with OpenGL camera settings.\n",
        "    _, _, _, _, seg_img = pybullet.getCameraImage(\n",
        "        width=image_size[1],\n",
        "        height=image_size[0],\n",
        "        viewMatrix=viewm,\n",
        "        projectionMatrix=projm,\n",
        "        shadow=1,\n",
        "        flags=pybullet.ER_SEGMENTATION_MASK_OBJECT_AND_LINKINDEX,\n",
        "        renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n",
        "\n",
        "    intrinsics = np.float32(intrinsics).reshape(3, 3)\n",
        "    return seg_img, position, orientation, intrinsics\n",
        "\n",
        "  def render_image(self, image_size=(720, 720), intrinsics=(360., 0, 360., 0, 360., 360., 0, 0, 1)):\n",
        "\n",
        "    # Camera parameters.\n",
        "    position = (0, -0.85, 0.4)\n",
        "    orientation = (np.pi / 4 + np.pi / 48, np.pi, np.pi)\n",
        "    orientation = pybullet.getQuaternionFromEuler(orientation)\n",
        "    zrange = (0.01, 10.)\n",
        "    noise=True\n",
        "\n",
        "    # OpenGL camera settings.\n",
        "    lookdir = np.float32([0, 0, 1]).reshape(3, 1)\n",
        "    updir = np.float32([0, -1, 0]).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotm = np.float32(rotation).reshape(3, 3)\n",
        "    lookdir = (rotm @ lookdir).reshape(-1)\n",
        "    updir = (rotm @ updir).reshape(-1)\n",
        "    lookat = position + lookdir\n",
        "    focal_len = intrinsics[0]\n",
        "    znear, zfar = (0.01, 10.)\n",
        "    viewm = pybullet.computeViewMatrix(position, lookat, updir)\n",
        "    fovh = (image_size[0] / 2) / focal_len\n",
        "    fovh = 180 * np.arctan(fovh) * 2 / np.pi\n",
        "\n",
        "    # Notes: 1) FOV is vertical FOV 2) aspect must be float\n",
        "    aspect_ratio = image_size[1] / image_size[0]\n",
        "    projm = pybullet.computeProjectionMatrixFOV(fovh, aspect_ratio, znear, zfar)\n",
        "\n",
        "    # Render with OpenGL camera settings.\n",
        "    _, _, color, depth, segm = pybullet.getCameraImage(\n",
        "        width=image_size[1],\n",
        "        height=image_size[0],\n",
        "        viewMatrix=viewm,\n",
        "        projectionMatrix=projm,\n",
        "        shadow=1,\n",
        "        flags=pybullet.ER_SEGMENTATION_MASK_OBJECT_AND_LINKINDEX,\n",
        "        renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n",
        "\n",
        "    # Get color image.\n",
        "    color_image_size = (image_size[0], image_size[1], 4)\n",
        "    color = np.array(color, dtype=np.uint8).reshape(color_image_size)\n",
        "    color = color[:, :, :3]  # remove alpha channel\n",
        "    if noise:\n",
        "      color = np.int32(color)\n",
        "      color += np.int32(np.random.normal(0, 3, color.shape))\n",
        "      color = np.uint8(np.clip(color, 0, 255))\n",
        "\n",
        "    # Get depth image.\n",
        "    depth_image_size = (image_size[0], image_size[1])\n",
        "    zbuffer = np.float32(depth).reshape(depth_image_size)\n",
        "    depth = (zfar + znear - (2 * zbuffer - 1) * (zfar - znear))\n",
        "    depth = (2 * znear * zfar) / depth\n",
        "    if noise:\n",
        "      depth += np.random.normal(0, 0.003, depth.shape)\n",
        "\n",
        "    intrinsics = np.float32(intrinsics).reshape(3, 3)\n",
        "    return color, depth, position, orientation, intrinsics\n",
        "\n",
        "  def get_pointcloud(self, depth, intrinsics):\n",
        "    \"\"\"Get 3D pointcloud from perspective depth image.\n",
        "    Args:\n",
        "      depth: HxW float array of perspective depth in meters.\n",
        "      intrinsics: 3x3 float array of camera intrinsics matrix.\n",
        "    Returns:\n",
        "      points: HxWx3 float array of 3D points in camera coordinates.\n",
        "    \"\"\"\n",
        "    height, width = depth.shape\n",
        "    xlin = np.linspace(0, width - 1, width)\n",
        "    ylin = np.linspace(0, height - 1, height)\n",
        "    px, py = np.meshgrid(xlin, ylin)\n",
        "    px = (px - intrinsics[0, 2]) * (depth / intrinsics[0, 0])\n",
        "    py = (py - intrinsics[1, 2]) * (depth / intrinsics[1, 1])\n",
        "    points = np.float32([px, py, depth]).transpose(1, 2, 0)\n",
        "    return points\n",
        "\n",
        "  def transform_pointcloud(self, points, transform):\n",
        "    \"\"\"Apply rigid transformation to 3D pointcloud.\n",
        "    Args:\n",
        "      points: HxWx3 float array of 3D points in camera coordinates.\n",
        "      transform: 4x4 float array representing a rigid transformation matrix.\n",
        "    Returns:\n",
        "      points: HxWx3 float array of transformed 3D points.\n",
        "    \"\"\"\n",
        "    padding = ((0, 0), (0, 0), (0, 1))\n",
        "    homogen_points = np.pad(points.copy(), padding,\n",
        "                            'constant', constant_values=1)\n",
        "    for i in range(3):\n",
        "      points[Ellipsis, i] = np.sum(transform[i, :] * homogen_points, axis=-1)\n",
        "    return points\n",
        "\n",
        "  def get_heightmap(self, points, colors, bounds, pixel_size):\n",
        "    \"\"\"Get top-down (z-axis) orthographic heightmap image from 3D pointcloud.\n",
        "    Args:\n",
        "      points: HxWx3 float array of 3D points in world coordinates.\n",
        "      colors: HxWx3 uint8 array of values in range 0-255 aligned with points.\n",
        "      bounds: 3x2 float array of values (rows: X,Y,Z; columns: min,max) defining\n",
        "        region in 3D space to generate heightmap in world coordinates.\n",
        "      pixel_size: float defining size of each pixel in meters.\n",
        "    Returns:\n",
        "      heightmap: HxW float array of height (from lower z-bound) in meters.\n",
        "      colormap: HxWx3 uint8 array of backprojected color aligned with heightmap.\n",
        "      xyzmap: HxWx3 float array of XYZ points in world coordinates.\n",
        "    \"\"\"\n",
        "    width = int(np.round((bounds[0, 1] - bounds[0, 0]) / pixel_size))\n",
        "    height = int(np.round((bounds[1, 1] - bounds[1, 0]) / pixel_size))\n",
        "    heightmap = np.zeros((height, width), dtype=np.float32)\n",
        "    colormap = np.zeros((height, width, colors.shape[-1]), dtype=np.uint8)\n",
        "    xyzmap = np.zeros((height, width, 3), dtype=np.float32)\n",
        "\n",
        "    # Filter out 3D points that are outside of the predefined bounds.\n",
        "    ix = (points[Ellipsis, 0] >= bounds[0, 0]) & (points[Ellipsis, 0] < bounds[0, 1])\n",
        "    iy = (points[Ellipsis, 1] >= bounds[1, 0]) & (points[Ellipsis, 1] < bounds[1, 1])\n",
        "    iz = (points[Ellipsis, 2] >= bounds[2, 0]) & (points[Ellipsis, 2] < bounds[2, 1])\n",
        "    valid = ix & iy & iz\n",
        "    points = points[valid]\n",
        "    colors = colors[valid]\n",
        "\n",
        "    # Sort 3D points by z-value, which works with array assignment to simulate\n",
        "    # z-buffering for rendering the heightmap image.\n",
        "    iz = np.argsort(points[:, -1])\n",
        "    points, colors = points[iz], colors[iz]\n",
        "    px = np.int32(np.floor((points[:, 0] - bounds[0, 0]) / pixel_size))\n",
        "    py = np.int32(np.floor((points[:, 1] - bounds[1, 0]) / pixel_size))\n",
        "    px = np.clip(px, 0, width - 1)\n",
        "    py = np.clip(py, 0, height - 1)\n",
        "    heightmap[py, px] = points[:, 2] - bounds[2, 0]\n",
        "    for c in range(colors.shape[-1]):\n",
        "      colormap[py, px, c] = colors[:, c]\n",
        "      xyzmap[py, px, c] = points[:, c]\n",
        "    colormap = colormap[::-1, :, :]  # Flip up-down.\n",
        "    xv, yv = np.meshgrid(np.linspace(BOUNDS[0, 0], BOUNDS[0, 1], height),\n",
        "                         np.linspace(BOUNDS[1, 0], BOUNDS[1, 1], width))\n",
        "    xyzmap[:, :, 0] = xv\n",
        "    xyzmap[:, :, 1] = yv\n",
        "    xyzmap = xyzmap[::-1, :, :]  # Flip up-down.\n",
        "    heightmap = heightmap[::-1, :]  # Flip up-down.\n",
        "    return heightmap, colormap, xyzmap\n",
        "\n",
        "  def on_top_of(self, obj_a, obj_b):\n",
        "    \"\"\"\n",
        "    check if obj_a is on top of obj_b\n",
        "    condition 1: l2 distance on xy plane is less than a threshold\n",
        "    condition 2: obj_a is higher than obj_b\n",
        "    \"\"\"\n",
        "    obj_a_pos = self.get_obj_pos(obj_a)\n",
        "    obj_b_pos = self.get_obj_pos(obj_b)\n",
        "    xy_dist = np.linalg.norm(obj_a_pos[:2] - obj_b_pos[:2])\n",
        "    if obj_b in CORNER_POS:\n",
        "      is_near = xy_dist < 0.06\n",
        "      return is_near\n",
        "    elif 'bowl' in obj_b:\n",
        "      is_near = xy_dist < 0.06\n",
        "      is_higher = obj_a_pos[2] > obj_b_pos[2]\n",
        "      return is_near and is_higher\n",
        "    else:\n",
        "      is_near = xy_dist < 0.04\n",
        "      is_higher = obj_a_pos[2] > obj_b_pos[2]\n",
        "      return is_near and is_higher\n",
        "\n",
        "  def get_obj_id(self, obj_name):\n",
        "    # print(f'looking for {obj_name}')\n",
        "    try:\n",
        "      if obj_name in self.obj_name_to_id:\n",
        "        obj_id = self.obj_name_to_id[obj_name]\n",
        "      else:\n",
        "        obj_name = obj_name.replace('circle', 'bowl').replace('square', 'block').replace('small', '').strip()\n",
        "        obj_id = self.obj_name_to_id[obj_name]\n",
        "    except:\n",
        "      print(f'requested_name=\"{obj_name}\"')\n",
        "      print(f'available_objects_and_id=\"{self.obj_name_to_id}')\n",
        "    return obj_id\n",
        "\n",
        "  def get_obj_pos(self, obj_name):\n",
        "    obj_name = obj_name.replace('the', '').replace('_', ' ').strip()\n",
        "    if obj_name in CORNER_POS:\n",
        "      position = np.float32(np.array(CORNER_POS[obj_name]))\n",
        "    else:\n",
        "      pick_id = self.get_obj_id(obj_name)\n",
        "      pose = pybullet.getBasePositionAndOrientation(pick_id)\n",
        "      position = np.float32(pose[0])\n",
        "    return position\n",
        "\n",
        "  def get_bounding_box(self, obj_name):\n",
        "    obj_id = self.get_obj_id(obj_name)\n",
        "    return pybullet.getAABB(obj_id)\n",
        "\n",
        "  def save_video(self, path):\n",
        "    imageio.mimsave(path, self.cache_video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_6S4u62sDVKB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Gym-style environment code\n",
        "\n",
        "class PushEnv():\n",
        "\n",
        "  def __init__(self, render=False, high_res=False, high_frame_rate=False, test=True):\n",
        "    self.dt = 1/480\n",
        "    self.sim_step = 0\n",
        "\n",
        "    # Configure and start PyBullet.\n",
        "    # python3 -m pybullet_utils.runServer\n",
        "    # pybullet.connect(pybullet.SHARED_MEMORY)  # pybullet.GUI for local GUI.\n",
        "    if test:\n",
        "      pybullet.connect(pybullet.GUI)\n",
        "    else:\n",
        "      pybullet.connect(pybullet.DIRECT)\n",
        "\n",
        "    # pybullet.connect(pybullet.DIRECT)  # pybullet.GUI for local GUI.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_GUI, 0)\n",
        "    pybullet.setPhysicsEngineParameter(enableFileCaching=0)\n",
        "    assets_path = os.path.dirname(os.path.abspath(\"\"))\n",
        "    pybullet.setAdditionalSearchPath(assets_path)\n",
        "    pybullet.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "    pybullet.setTimeStep(self.dt)\n",
        "\n",
        "    self.home_joints = (np.pi / 2, -np.pi / 2, np.pi / 2, -np.pi / 2, 3 * np.pi / 2, 0)  # Joint angles: (J0, J1, J2, J3, J4, J5).\n",
        "    self.home_ee_euler = (np.pi, 0, np.pi)  # (RX, RY, RZ) rotation in Euler angles.\n",
        "    self.ee_link_id = 9  # Link ID of UR5 end effector.\n",
        "    self.tip_link_id = 10  # Link ID of gripper finger tips.\n",
        "    self.gripper = None\n",
        "\n",
        "    self.render = render\n",
        "    self.high_res = high_res\n",
        "    self.high_frame_rate = high_frame_rate\n",
        "\n",
        "  def reset(self, object_list):\n",
        "    pybullet.resetSimulation(pybullet.RESET_USE_DEFORMABLE_WORLD)\n",
        "    pybullet.setGravity(0, 0, -9.8)\n",
        "    self.cache_video = []\n",
        "\n",
        "    # Temporarily disable rendering to load URDFs faster.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_RENDERING, 0)\n",
        "\n",
        "    # Add robot.\n",
        "    pybullet.loadURDF(\"plane.urdf\", [0, 0, -0.001])\n",
        "    self.robot_id = pybullet.loadURDF(\"ur5e/ur5e.urdf\", [0, 0, 0], flags=pybullet.URDF_USE_MATERIAL_COLORS_FROM_MTL)\n",
        "    self.ghost_id = pybullet.loadURDF(\"ur5e/ur5e.urdf\", [0, 0, -10])  # For forward kinematics.\n",
        "    self.joint_ids = [pybullet.getJointInfo(self.robot_id, i) for i in range(pybullet.getNumJoints(self.robot_id))]\n",
        "    self.joint_ids = [j[0] for j in self.joint_ids if j[2] == pybullet.JOINT_REVOLUTE]\n",
        "\n",
        "    # Move robot to home configuration.\n",
        "    for i in range(len(self.joint_ids)):\n",
        "      pybullet.resetJointState(self.robot_id, self.joint_ids[i], self.home_joints[i])\n",
        "\n",
        "    # Add gripper.\n",
        "    if self.gripper is not None:\n",
        "      while self.gripper.constraints_thread.is_alive():\n",
        "        self.constraints_thread_active = False\n",
        "    self.gripper = Robotiq2F85(self.robot_id, self.ee_link_id)\n",
        "    self.gripper.release()\n",
        "\n",
        "    # Add workspace.\n",
        "    plane_shape = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[0.3, 0.3, 0.001])\n",
        "    plane_visual = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[0.3, 0.3, 0.001])\n",
        "    plane_id = pybullet.createMultiBody(0, plane_shape, plane_visual, basePosition=[0, -0.5, 0])\n",
        "    pybullet.changeVisualShape(plane_id, -1, rgbaColor=[0.2, 0.2, 0.2, 1.0])\n",
        "\n",
        "    # Load objects according to config.\n",
        "    self.object_list = object_list\n",
        "    self.obj_name_to_id = {}\n",
        "    obj_xyz = np.zeros((0, 3))\n",
        "    for obj_name in object_list:\n",
        "      if ('block' in obj_name) or ('bowl' in obj_name):\n",
        "\n",
        "        # Get random position 15cm+ from other objects.\n",
        "        while True:\n",
        "          rand_x = np.random.uniform(BOUNDS[0, 0] + 0.1, BOUNDS[0, 1] - 0.1)\n",
        "          rand_y = np.random.uniform(BOUNDS[1, 0] + 0.1, BOUNDS[1, 1] - 0.1)\n",
        "          rand_xyz = np.float32([rand_x, rand_y, 0.03]).reshape(1, 3)\n",
        "          if len(obj_xyz) == 0:\n",
        "            obj_xyz = np.concatenate((obj_xyz, rand_xyz), axis=0)\n",
        "            break\n",
        "          else:\n",
        "            nn_dist = np.min(np.linalg.norm(obj_xyz - rand_xyz, axis=1)).squeeze()\n",
        "            if nn_dist > 0.15:\n",
        "              obj_xyz = np.concatenate((obj_xyz, rand_xyz), axis=0)\n",
        "              break\n",
        "\n",
        "        object_color = COLORS[obj_name.split(' ')[0]]\n",
        "        object_type = obj_name.split(' ')[1]\n",
        "        object_position = rand_xyz.squeeze()\n",
        "        if object_type == 'block':\n",
        "          object_shape = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02])\n",
        "          object_visual = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02])\n",
        "          object_id = pybullet.createMultiBody(0.01, object_shape, object_visual, basePosition=object_position)\n",
        "        elif object_type == 'bowl':\n",
        "          object_position[2] = 0\n",
        "          object_id = pybullet.loadURDF(\"bowl/bowl.urdf\", object_position, useFixedBase=1)\n",
        "        pybullet.changeVisualShape(object_id, -1, rgbaColor=object_color)\n",
        "        self.obj_name_to_id[obj_name] = object_id\n",
        "\n",
        "\n",
        "    # Re-enable rendering.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_RENDERING, 1)\n",
        "\n",
        "    for _ in range(200):\n",
        "      pybullet.stepSimulation()\n",
        "\n",
        "    # record object positions at reset\n",
        "    self.init_pos = {name: self.get_obj_pos(name) for name in object_list}\n",
        "\n",
        "    return self.get_observation()\n",
        "\n",
        "  def servoj(self, joints):\n",
        "    \"\"\"Move to target joint positions with position control.\"\"\"\n",
        "    pybullet.setJointMotorControlArray(\n",
        "      bodyIndex=self.robot_id,\n",
        "      jointIndices=self.joint_ids,\n",
        "      controlMode=pybullet.POSITION_CONTROL,\n",
        "      targetPositions=joints,\n",
        "      positionGains=[0.01]*6)\n",
        "\n",
        "  def movep(self, position):\n",
        "    \"\"\"Move to target end effector position.\"\"\"\n",
        "    joints = pybullet.calculateInverseKinematics(\n",
        "        bodyUniqueId=self.robot_id,\n",
        "        endEffectorLinkIndex=self.tip_link_id,\n",
        "        targetPosition=position,\n",
        "        targetOrientation=pybullet.getQuaternionFromEuler(self.home_ee_euler),\n",
        "        maxNumIterations=100)\n",
        "    self.servoj(joints)\n",
        "\n",
        "  def get_ee_pos(self):\n",
        "    ee_xyz = np.float32(pybullet.getLinkState(self.robot_id, self.tip_link_id)[0])\n",
        "    return ee_xyz\n",
        "\n",
        "  def step(self, action=None):\n",
        "    \"\"\"Do pick and place motion primitive.\"\"\"\n",
        "    obj_pos, destination_pos = action['push'].copy(), action['to'].copy()\n",
        "\n",
        "    direction = destination_pos - obj_pos\n",
        "    threshold = 0.1\n",
        "\n",
        "    hover_height = 0.2\n",
        "    push_height = 0.025\n",
        "\n",
        "    # Set fixed primitive z-heights.\n",
        "    hover_xyz = np.float32([obj_pos[0]-direction[0]*threshold, obj_pos[1]-direction[1]*threshold, hover_height])\n",
        "    if obj_pos.shape[-1] == 2:\n",
        "      push_xyz = np.append(obj_pos, push_height)\n",
        "    else:\n",
        "      push_xyz = obj_pos\n",
        "      push_xyz[2] = push_height\n",
        "\n",
        "    push_xyz[0] -= direction[0]*threshold\n",
        "    push_xyz[1] -= direction[1]*threshold\n",
        "\n",
        "    if destination_pos.shape[-1] == 2:\n",
        "      destination_xyz = np.append(destination_pos, push_height)\n",
        "    else:\n",
        "      destination_xyz = destination_pos\n",
        "      destination_xyz[2] = push_height\n",
        "\n",
        "    print(f'destination_xyz: {destination_xyz}')\n",
        "    print(f'push_xyz: {push_xyz}')\n",
        "    print(f'Distance between obj and dest: {np.linalg.norm(destination_xyz-push_xyz, np.inf)}')\n",
        "    # Move to object.\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    self.gripper.activate()\n",
        "    for _ in range(240):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(hover_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    while np.linalg.norm(push_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(push_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    # Move to target location.\n",
        "    while np.linalg.norm(destination_xyz - ee_xyz) > 0.01:\n",
        "      tmp_dir =  ee_xyz+threshold*direction*1000\n",
        "      self.movep(destination_xyz)\n",
        "      for _ in range(50):\n",
        "        self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    finish_xyz = destination_xyz\n",
        "    finish_xyz[2] = hover_height\n",
        "    while np.linalg.norm(finish_xyz-ee_xyz) > 0.01:\n",
        "      self.movep(finish_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "    self.gripper.release()\n",
        "    for  _ in range(250):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    observation = self.get_observation()\n",
        "    reward = self.get_reward()\n",
        "    done = False\n",
        "    info = {}\n",
        "    return observation, reward, done, info\n",
        "\n",
        "  def set_alpha_transparency(self, alpha: float) -> None:\n",
        "    for id in range(20):\n",
        "      visual_shape_data = pybullet.getVisualShapeData(id)\n",
        "      for i in range(len(visual_shape_data)):\n",
        "        object_id, link_index, _, _, _, _, _, rgba_color = visual_shape_data[i]\n",
        "        rgba_color = list(rgba_color[0:3]) +  [alpha]\n",
        "        pybullet.changeVisualShape(\n",
        "            self.robot_id, linkIndex=i, rgbaColor=rgba_color)\n",
        "        pybullet.changeVisualShape(\n",
        "            self.gripper.body, linkIndex=i, rgbaColor=rgba_color)\n",
        "\n",
        "  def step_sim_and_render(self):\n",
        "    pybullet.stepSimulation()\n",
        "    self.sim_step += 1\n",
        "\n",
        "    interval = 40 if self.high_frame_rate else 60\n",
        "    # Render current image at 8 FPS.\n",
        "    if self.sim_step % interval == 0 and self.render:\n",
        "      self.cache_video.append(self.get_camera_image())\n",
        "\n",
        "  def get_camera_image(self):\n",
        "    if not self.high_res:\n",
        "      image_size = (240, 240)\n",
        "      intrinsics = (120., 0, 120., 0, 120., 120., 0, 0, 1)\n",
        "    else:\n",
        "      image_size=(360, 360)\n",
        "      intrinsics=(180., 0, 180., 0, 180., 180., 0, 0, 1)\n",
        "    color, _, _, _, _ = self.render_image(image_size, intrinsics)\n",
        "    return color\n",
        "\n",
        "  def get_reward(self):\n",
        "    return None\n",
        "\n",
        "  def get_observation(self):\n",
        "    observation = {}\n",
        "\n",
        "    # Render current image.\n",
        "    color, depth, position, orientation, intrinsics = self.render_image()\n",
        "\n",
        "    # Get heightmaps and colormaps.\n",
        "    points = self.get_pointcloud(depth, intrinsics)\n",
        "    position = np.float32(position).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotation = np.float32(rotation).reshape(3, 3)\n",
        "    transform = np.eye(4)\n",
        "    transform[:3, :] = np.hstack((rotation, position))\n",
        "    points = self.transform_pointcloud(points, transform)\n",
        "    heightmap, colormap, xyzmap = self.get_heightmap(points, color, BOUNDS, PIXEL_SIZE)\n",
        "\n",
        "    observation[\"image\"] = colormap\n",
        "    observation[\"xyzmap\"] = xyzmap\n",
        "\n",
        "    return observation\n",
        "\n",
        "  def render_image(self, image_size=(720, 720), intrinsics=(360., 0, 360., 0, 360., 360., 0, 0, 1)):\n",
        "\n",
        "    # Camera parameters.\n",
        "    position = (0, -0.85, 0.4)\n",
        "    orientation = (np.pi / 4 + np.pi / 48, np.pi, np.pi)\n",
        "    orientation = pybullet.getQuaternionFromEuler(orientation)\n",
        "    zrange = (0.01, 10.)\n",
        "    noise=True\n",
        "\n",
        "    # OpenGL camera settings.\n",
        "    lookdir = np.float32([0, 0, 1]).reshape(3, 1)\n",
        "    updir = np.float32([0, -1, 0]).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotm = np.float32(rotation).reshape(3, 3)\n",
        "    lookdir = (rotm @ lookdir).reshape(-1)\n",
        "    updir = (rotm @ updir).reshape(-1)\n",
        "    lookat = position + lookdir\n",
        "    focal_len = intrinsics[0]\n",
        "    znear, zfar = (0.01, 10.)\n",
        "    viewm = pybullet.computeViewMatrix(position, lookat, updir)\n",
        "    fovh = (image_size[0] / 2) / focal_len\n",
        "    fovh = 180 * np.arctan(fovh) * 2 / np.pi\n",
        "\n",
        "    # Notes: 1) FOV is vertical FOV 2) aspect must be float\n",
        "    aspect_ratio = image_size[1] / image_size[0]\n",
        "    projm = pybullet.computeProjectionMatrixFOV(fovh, aspect_ratio, znear, zfar)\n",
        "\n",
        "    # Render with OpenGL camera settings.\n",
        "    _, _, color, depth, segm = pybullet.getCameraImage(\n",
        "        width=image_size[1],\n",
        "        height=image_size[0],\n",
        "        viewMatrix=viewm,\n",
        "        projectionMatrix=projm,\n",
        "        shadow=1,\n",
        "        flags=pybullet.ER_SEGMENTATION_MASK_OBJECT_AND_LINKINDEX,\n",
        "        renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n",
        "\n",
        "    # Get color image.\n",
        "    color_image_size = (image_size[0], image_size[1], 4)\n",
        "    color = np.array(color, dtype=np.uint8).reshape(color_image_size)\n",
        "    color = color[:, :, :3]  # remove alpha channel\n",
        "    if noise:\n",
        "      color = np.int32(color)\n",
        "      color += np.int32(np.random.normal(0, 3, color.shape))\n",
        "      color = np.uint8(np.clip(color, 0, 255))\n",
        "\n",
        "    # Get depth image.\n",
        "    depth_image_size = (image_size[0], image_size[1])\n",
        "    zbuffer = np.float32(depth).reshape(depth_image_size)\n",
        "    depth = (zfar + znear - (2 * zbuffer - 1) * (zfar - znear))\n",
        "    depth = (2 * znear * zfar) / depth\n",
        "    if noise:\n",
        "      depth += np.random.normal(0, 0.003, depth.shape)\n",
        "\n",
        "    intrinsics = np.float32(intrinsics).reshape(3, 3)\n",
        "    return color, depth, position, orientation, intrinsics\n",
        "\n",
        "  def get_pointcloud(self, depth, intrinsics):\n",
        "    \"\"\"Get 3D pointcloud from perspective depth image.\n",
        "    Args:\n",
        "      depth: HxW float array of perspective depth in meters.\n",
        "      intrinsics: 3x3 float array of camera intrinsics matrix.\n",
        "    Returns:\n",
        "      points: HxWx3 float array of 3D points in camera coordinates.\n",
        "    \"\"\"\n",
        "    height, width = depth.shape\n",
        "    xlin = np.linspace(0, width - 1, width)\n",
        "    ylin = np.linspace(0, height - 1, height)\n",
        "    px, py = np.meshgrid(xlin, ylin)\n",
        "    px = (px - intrinsics[0, 2]) * (depth / intrinsics[0, 0])\n",
        "    py = (py - intrinsics[1, 2]) * (depth / intrinsics[1, 1])\n",
        "    points = np.float32([px, py, depth]).transpose(1, 2, 0)\n",
        "    return points\n",
        "\n",
        "  def transform_pointcloud(self, points, transform):\n",
        "    \"\"\"Apply rigid transformation to 3D pointcloud.\n",
        "    Args:\n",
        "      points: HxWx3 float array of 3D points in camera coordinates.\n",
        "      transform: 4x4 float array representing a rigid transformation matrix.\n",
        "    Returns:\n",
        "      points: HxWx3 float array of transformed 3D points.\n",
        "    \"\"\"\n",
        "    padding = ((0, 0), (0, 0), (0, 1))\n",
        "    homogen_points = np.pad(points.copy(), padding,\n",
        "                            'constant', constant_values=1)\n",
        "    for i in range(3):\n",
        "      points[Ellipsis, i] = np.sum(transform[i, :] * homogen_points, axis=-1)\n",
        "    return points\n",
        "\n",
        "  def get_heightmap(self, points, colors, bounds, pixel_size):\n",
        "    \"\"\"Get top-down (z-axis) orthographic heightmap image from 3D pointcloud.\n",
        "    Args:\n",
        "      points: HxWx3 float array of 3D points in world coordinates.\n",
        "      colors: HxWx3 uint8 array of values in range 0-255 aligned with points.\n",
        "      bounds: 3x2 float array of values (rows: X,Y,Z; columns: min,max) defining\n",
        "        region in 3D space to generate heightmap in world coordinates.\n",
        "      pixel_size: float defining size of each pixel in meters.\n",
        "    Returns:\n",
        "      heightmap: HxW float array of height (from lower z-bound) in meters.\n",
        "      colormap: HxWx3 uint8 array of backprojected color aligned with heightmap.\n",
        "      xyzmap: HxWx3 float array of XYZ points in world coordinates.\n",
        "    \"\"\"\n",
        "    width = int(np.round((bounds[0, 1] - bounds[0, 0]) / pixel_size))\n",
        "    height = int(np.round((bounds[1, 1] - bounds[1, 0]) / pixel_size))\n",
        "    heightmap = np.zeros((height, width), dtype=np.float32)\n",
        "    colormap = np.zeros((height, width, colors.shape[-1]), dtype=np.uint8)\n",
        "    xyzmap = np.zeros((height, width, 3), dtype=np.float32)\n",
        "\n",
        "    # Filter out 3D points that are outside of the predefined bounds.\n",
        "    ix = (points[Ellipsis, 0] >= bounds[0, 0]) & (points[Ellipsis, 0] < bounds[0, 1])\n",
        "    iy = (points[Ellipsis, 1] >= bounds[1, 0]) & (points[Ellipsis, 1] < bounds[1, 1])\n",
        "    iz = (points[Ellipsis, 2] >= bounds[2, 0]) & (points[Ellipsis, 2] < bounds[2, 1])\n",
        "    valid = ix & iy & iz\n",
        "    points = points[valid]\n",
        "    colors = colors[valid]\n",
        "\n",
        "    # Sort 3D points by z-value, which works with array assignment to simulate\n",
        "    # z-buffering for rendering the heightmap image.\n",
        "    iz = np.argsort(points[:, -1])\n",
        "    points, colors = points[iz], colors[iz]\n",
        "    px = np.int32(np.floor((points[:, 0] - bounds[0, 0]) / pixel_size))\n",
        "    py = np.int32(np.floor((points[:, 1] - bounds[1, 0]) / pixel_size))\n",
        "    px = np.clip(px, 0, width - 1)\n",
        "    py = np.clip(py, 0, height - 1)\n",
        "    heightmap[py, px] = points[:, 2] - bounds[2, 0]\n",
        "    for c in range(colors.shape[-1]):\n",
        "      colormap[py, px, c] = colors[:, c]\n",
        "      xyzmap[py, px, c] = points[:, c]\n",
        "    colormap = colormap[::-1, :, :]  # Flip up-down.\n",
        "    xv, yv = np.meshgrid(np.linspace(BOUNDS[0, 0], BOUNDS[0, 1], height),\n",
        "                         np.linspace(BOUNDS[1, 0], BOUNDS[1, 1], width))\n",
        "    xyzmap[:, :, 0] = xv\n",
        "    xyzmap[:, :, 1] = yv\n",
        "    xyzmap = xyzmap[::-1, :, :]  # Flip up-down.\n",
        "    heightmap = heightmap[::-1, :]  # Flip up-down.\n",
        "    return heightmap, colormap, xyzmap\n",
        "\n",
        "  def on_top_of(self, obj_a, obj_b):\n",
        "    \"\"\"\n",
        "    check if obj_a is on top of obj_b\n",
        "    condition 1: l2 distance on xy plane is less than a threshold\n",
        "    condition 2: obj_a is higher than obj_b\n",
        "    \"\"\"\n",
        "    obj_a_pos = self.get_obj_pos(obj_a)\n",
        "    obj_b_pos = self.get_obj_pos(obj_b)\n",
        "    xy_dist = np.linalg.norm(obj_a_pos[:2] - obj_b_pos[:2])\n",
        "    if obj_b in CORNER_POS:\n",
        "      is_near = xy_dist < 0.06\n",
        "      return is_near\n",
        "    elif 'bowl' in obj_b:\n",
        "      is_near = xy_dist < 0.06\n",
        "      is_higher = obj_a_pos[2] > obj_b_pos[2]\n",
        "      return is_near and is_higher\n",
        "    else:\n",
        "      is_near = xy_dist < 0.04\n",
        "      is_higher = obj_a_pos[2] > obj_b_pos[2]\n",
        "      return is_near and is_higher\n",
        "\n",
        "  def get_obj_id(self, obj_name):\n",
        "    try:\n",
        "      if obj_name in self.obj_name_to_id:\n",
        "        obj_id = self.obj_name_to_id[obj_name]\n",
        "      else:\n",
        "        obj_name = obj_name.replace('circle', 'bowl').replace('square', 'block').replace('small', '').strip()\n",
        "        obj_id = self.obj_name_to_id[obj_name]\n",
        "    except:\n",
        "      print(f'requested_name=\"{obj_name}\"')\n",
        "      print(f'available_objects_and_id=\"{self.obj_name_to_id}')\n",
        "    return obj_id\n",
        "\n",
        "  def get_obj_pos(self, obj_name):\n",
        "    obj_name = obj_name.replace('the', '').replace('_', ' ').strip()\n",
        "    if obj_name in CORNER_POS:\n",
        "      position = np.float32(np.array(CORNER_POS[obj_name]))\n",
        "    else:\n",
        "      pick_id = self.get_obj_id(obj_name)\n",
        "      pose = pybullet.getBasePositionAndOrientation(pick_id)\n",
        "      position = np.float32(pose[0])\n",
        "    return position\n",
        "\n",
        "  def get_bounding_box(self, obj_name):\n",
        "    obj_id = self.get_obj_id(obj_name)\n",
        "    return pybullet.getAABB(obj_id)\n",
        "\n",
        "  def save_video(self, path):\n",
        "    imageio.mimsave(path, self.cache_video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MXXkGpTsDa1n"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Gym-style environment code\n",
        "\n",
        "class GeneralEnv():\n",
        "\n",
        "  def __init__(self, render=False, high_res=False, high_frame_rate=False, test=False):\n",
        "    self.dt = 1/480\n",
        "    self.sim_step = 0\n",
        "\n",
        "    # Configure and start PyBullet.\n",
        "    # python3 -m pybullet_utils.runServer\n",
        "    # pybullet.connect(pybullet.SHARED_MEMORY)  # pybullet.GUI for local GUI.\n",
        "\n",
        "    if test:\n",
        "      pybullet.connect(pybullet.GUI)\n",
        "    else:\n",
        "      pybullet.connect(pybullet.DIRECT)  # pybullet.GUI for local GUI.\n",
        "\n",
        "\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_GUI, 0)\n",
        "    pybullet.setPhysicsEngineParameter(enableFileCaching=0)\n",
        "    assets_path = os.path.dirname(os.path.abspath(\"\"))\n",
        "    pybullet.setAdditionalSearchPath(assets_path)\n",
        "    pybullet.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "    pybullet.setTimeStep(self.dt)\n",
        "\n",
        "    self.home_joints = (np.pi / 2, -np.pi / 2, np.pi / 2, -np.pi / 2, 3 * np.pi / 2, 0)  # Joint angles: (J0, J1, J2, J3, J4, J5).\n",
        "    self.home_ee_euler = (np.pi, 0, np.pi)  # (RX, RY, RZ) rotation in Euler angles.\n",
        "    self.ee_link_id = 9  # Link ID of UR5 end effector.\n",
        "    self.tip_link_id = 10  # Link ID of gripper finger tips.\n",
        "    self.gripper = None\n",
        "\n",
        "    self.render = render\n",
        "    self.high_res = high_res\n",
        "    self.high_frame_rate = high_frame_rate\n",
        "    self.pickable_obj = []\n",
        "\n",
        "  def is_obj_pickable(self, obj_name):\n",
        "    return obj_name in self.pickable_obj\n",
        "\n",
        "  def reset(self, object_list, pickable_cfg):\n",
        "    pybullet.resetSimulation(pybullet.RESET_USE_DEFORMABLE_WORLD)\n",
        "    pybullet.setGravity(0, 0, -9.8)\n",
        "    self.cache_video = []\n",
        "\n",
        "    # Temporarily disable rendering to load URDFs faster.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_RENDERING, 0)\n",
        "\n",
        "    # Add robot.\n",
        "    pybullet.loadURDF(\"plane.urdf\", [0, 0, -0.001])\n",
        "    self.robot_id = pybullet.loadURDF(\"ur5e/ur5e.urdf\", [0, 0, 0], flags=pybullet.URDF_USE_MATERIAL_COLORS_FROM_MTL)\n",
        "    self.ghost_id = pybullet.loadURDF(\"ur5e/ur5e.urdf\", [0, 0, -10])  # For forward kinematics.\n",
        "    self.joint_ids = [pybullet.getJointInfo(self.robot_id, i) for i in range(pybullet.getNumJoints(self.robot_id))]\n",
        "    self.joint_ids = [j[0] for j in self.joint_ids if j[2] == pybullet.JOINT_REVOLUTE]\n",
        "\n",
        "    # Move robot to home configuration.\n",
        "    for i in range(len(self.joint_ids)):\n",
        "      pybullet.resetJointState(self.robot_id, self.joint_ids[i], self.home_joints[i])\n",
        "\n",
        "    # Add gripper.\n",
        "    if self.gripper is not None:\n",
        "      while self.gripper.constraints_thread.is_alive():\n",
        "        self.constraints_thread_active = False\n",
        "    self.gripper = Robotiq2F85(self.robot_id, self.ee_link_id)\n",
        "    self.gripper.release()\n",
        "\n",
        "    # Add workspace.\n",
        "    plane_shape = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[0.3, 0.3, 0.001])\n",
        "    plane_visual = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[0.3, 0.3, 0.001])\n",
        "    plane_id = pybullet.createMultiBody(0, plane_shape, plane_visual, basePosition=[0, -0.5, 0])\n",
        "    pybullet.changeVisualShape(plane_id, -1, rgbaColor=[0.2, 0.2, 0.2, 1.0])\n",
        "\n",
        "    # Load objects according to config.\n",
        "    self.object_list = object_list\n",
        "    self.obj_name_to_id = {}\n",
        "    obj_xyz = np.zeros((0, 3))\n",
        "\n",
        "    num_block = 0\n",
        "    first_block_pos = None\n",
        "    for obj_name in object_list:\n",
        "      if not pickable_cfg[obj_name]:\n",
        "        pass\n",
        "      else:\n",
        "        self.pickable_obj.append(obj_name)\n",
        "      if ('block' in obj_name) or ('bowl' in obj_name):\n",
        "        object_type = obj_name.split(' ')[1]\n",
        "\n",
        "        # Get random position 15cm+ from other objects.\n",
        "        while True:\n",
        "          rand_x = np.random.uniform(BOUNDS[0, 0] + 0.1, BOUNDS[0, 1] - 0.1)\n",
        "          rand_y = np.random.uniform(BOUNDS[1, 0] + 0.1, BOUNDS[1, 1] - 0.1)\n",
        "          rand_xyz = np.float32([rand_x, rand_y, 0.03]).reshape(1, 3)\n",
        "          if len(obj_xyz) == 0:\n",
        "            obj_xyz = np.concatenate((obj_xyz, rand_xyz), axis=0)\n",
        "            break\n",
        "          else:\n",
        "            nn_dist = np.min(np.linalg.norm(obj_xyz - rand_xyz, axis=1)).squeeze()\n",
        "            if nn_dist > 0.15:\n",
        "              obj_xyz = np.concatenate((obj_xyz, rand_xyz), axis=0)\n",
        "              break\n",
        "\n",
        "        object_color = COLORS[obj_name.split(' ')[0]]\n",
        "        object_type = obj_name.split(' ')[1]\n",
        "        object_position = rand_xyz.squeeze()\n",
        "        if object_type == 'block' and num_block == 0:\n",
        "          first_block_pos = object_position\n",
        "\n",
        "        if object_type == 'block' and num_block == 1:\n",
        "          object_position = first_block_pos\n",
        "          object_position[2] += 0.02\n",
        "\n",
        "        if object_type == 'block':\n",
        "          object_shape = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02])\n",
        "          object_visual = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[0.02, 0.02, 0.02])\n",
        "          object_id = pybullet.createMultiBody(0.01, object_shape, object_visual, basePosition=object_position)\n",
        "        elif object_type == 'bowl':\n",
        "          object_position[2] = 0\n",
        "          object_id = pybullet.loadURDF(\"bowl/bowl.urdf\", object_position, useFixedBase=1)\n",
        "        pybullet.changeVisualShape(object_id, -1, rgbaColor=object_color)\n",
        "        self.obj_name_to_id[obj_name] = object_id\n",
        "\n",
        "\n",
        "    # Re-enable rendering.\n",
        "    pybullet.configureDebugVisualizer(pybullet.COV_ENABLE_RENDERING, 1)\n",
        "\n",
        "    for _ in range(200):\n",
        "      pybullet.stepSimulation()\n",
        "\n",
        "    # record object positions at reset\n",
        "    self.init_pos = {name: self.get_obj_pos(name) for name in object_list}\n",
        "\n",
        "    return self.get_observation()\n",
        "\n",
        "  def servoj(self, joints):\n",
        "    \"\"\"Move to target joint positions with position control.\"\"\"\n",
        "    pybullet.setJointMotorControlArray(\n",
        "      bodyIndex=self.robot_id,\n",
        "      jointIndices=self.joint_ids,\n",
        "      controlMode=pybullet.POSITION_CONTROL,\n",
        "      targetPositions=joints,\n",
        "      positionGains=[0.01]*6)\n",
        "\n",
        "  def movep(self, position):\n",
        "    \"\"\"Move to target end effector position.\"\"\"\n",
        "    joints = pybullet.calculateInverseKinematics(\n",
        "        bodyUniqueId=self.robot_id,\n",
        "        endEffectorLinkIndex=self.tip_link_id,\n",
        "        targetPosition=position,\n",
        "        targetOrientation=pybullet.getQuaternionFromEuler(self.home_ee_euler),\n",
        "        maxNumIterations=100)\n",
        "    self.servoj(joints)\n",
        "\n",
        "  def get_ee_pos(self):\n",
        "    ee_xyz = np.float32(pybullet.getLinkState(self.robot_id, self.tip_link_id)[0])\n",
        "    return ee_xyz\n",
        "\n",
        "  def place(self, place_name, speed=1.):\n",
        "    # Move to place location.\n",
        "    print(f'Placing on {place_name}')\n",
        "    if place_name in self.object_list:\n",
        "      place_xyz = self.get_obj_pos(place_name)\n",
        "    else:\n",
        "      place_xyz = place_name\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    while np.linalg.norm(place_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(place_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    # Place down object.\n",
        "    while (not self.gripper.detect_contact()) and (place_xyz[2] > 0.03):\n",
        "      place_xyz[2] -= 0.001\n",
        "      self.movep(place_xyz)\n",
        "      for _ in range(3):\n",
        "        self.step_sim_and_render()\n",
        "\n",
        "    self.gripper.release()\n",
        "    for _ in range(240):\n",
        "      self.step_sim_and_render()\n",
        "    place_xyz[2] = 0.2\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    while np.linalg.norm(place_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(place_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "    place_xyz = np.float32([0, -0.5, 0.2])\n",
        "\n",
        "    while np.linalg.norm(place_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(place_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "    return True\n",
        "\n",
        "  def push(self, obj_name, to_name, speed=1.):\n",
        "    if to_name in self.object_list:\n",
        "      to_pos = self.get_obj_pos(to_name)\n",
        "    else:\n",
        "      to_pos = to_name\n",
        "\n",
        "    obj_pos = self.get_obj_pos(obj_name)\n",
        "\n",
        "    threshold = 0.1\n",
        "    hover_height = 0.2\n",
        "    push_height = 0.025\n",
        "\n",
        "    if len(to_pos) == 2:\n",
        "      to_pos = np.append(to_pos, push_height)\n",
        "\n",
        "    direction = to_pos - obj_pos\n",
        "    # Set fixed primitive z-heights.\n",
        "    hover_xyz = np.float32([obj_pos[0]-direction[0]*threshold, obj_pos[1]-direction[1]*threshold, hover_height])\n",
        "    if obj_pos.shape[-1] == 2:\n",
        "      push_xyz = np.append(obj_pos, push_height)\n",
        "    else:\n",
        "      push_xyz = obj_pos\n",
        "      push_xyz[2] = push_height\n",
        "    push_xyz[0] -= direction[0]*threshold\n",
        "    push_xyz[1] -= direction[1]*threshold\n",
        "    if to_pos.shape[-1] == 2:\n",
        "      destination_xyz = np.append(to_pos, push_height)\n",
        "    else:\n",
        "      destination_xyz = to_pos\n",
        "      destination_xyz[2] = push_height\n",
        "\n",
        "    # Move to object.\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "    self.gripper.activate() # Close gripper for stable contact\n",
        "\n",
        "    for _ in range(240):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(hover_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    while np.linalg.norm(push_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(push_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    # Move to place location.\n",
        "    while np.linalg.norm(destination_xyz - ee_xyz) > 0.01:\n",
        "      tmp_dir =  ee_xyz+threshold*direction*1000\n",
        "      self.movep(destination_xyz)\n",
        "      for _ in range(50):\n",
        "        self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    finish_xyz = destination_xyz\n",
        "    finish_xyz[2] = hover_height\n",
        "    while np.linalg.norm(finish_xyz-ee_xyz) > 0.01:\n",
        "      self.movep(finish_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "    self.gripper.release()\n",
        "    for  _ in range(250):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    return True\n",
        "\n",
        "  def pick(self, obj_name, speed=1.):\n",
        "    # Pick action\n",
        "    # print(f'Picking {obj_name}')\n",
        "    if obj_name not in self.object_list: # Unknown object error\n",
        "      raise PickFailure(name='pick_failure', reason='unknown object')\n",
        "      # raise NotImplementedError # TODO: Implement more excepetions\n",
        "    pick_pos = self.get_obj_pos(obj_name)\n",
        "\n",
        "    # Set fixed primitive z-heights.\n",
        "    hover_xyz = np.float32([pick_pos[0], pick_pos[1], 0.2])\n",
        "    if pick_pos.shape[-1] == 2:\n",
        "      pick_xyz = np.append(pick_pos, 0.025)\n",
        "    else:\n",
        "      pick_xyz = pick_pos\n",
        "      pick_xyz[2] = 0.025\n",
        "\n",
        "    ee_xyz = self.get_ee_pos()\n",
        "    while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(hover_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    while np.linalg.norm(pick_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(pick_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    self.gripper.activate()\n",
        "    for _ in range(240):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    is_pickable = self.is_obj_pickable(obj_name)\n",
        "    if not is_pickable:\n",
        "      for _ in range(240):\n",
        "        self.step_sim_and_render()\n",
        "      self.gripper.release()\n",
        "      for _ in range(240):\n",
        "        self.step_sim_and_render()\n",
        "      while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "        self.movep(hover_xyz)\n",
        "        self.step_sim_and_render()\n",
        "        ee_xyz = self.get_ee_pos()\n",
        "      for _ in range(50):\n",
        "        self.step_sim_and_render()\n",
        "      return False # Object cannot be picked\n",
        "\n",
        "    while np.linalg.norm(hover_xyz - ee_xyz) > 0.01:\n",
        "      self.movep(hover_xyz)\n",
        "      self.step_sim_and_render()\n",
        "      ee_xyz = self.get_ee_pos()\n",
        "\n",
        "    for _ in range(50):\n",
        "      self.step_sim_and_render()\n",
        "\n",
        "    return True\n",
        "\n",
        "  def step(self, action=None):\n",
        "    \"\"\"\n",
        "    Perform action according to the dict\n",
        "\n",
        "    Valid actions:\n",
        "      : pick obj_a\n",
        "      : place obj_b, pos_b\n",
        "      : push obj_a, obj_b/pos_b\n",
        "    Parameters:\n",
        "      : speed\n",
        "    \"\"\"\n",
        "    speed = 1.\n",
        "    if 'speed' in action.keys():\n",
        "      speed = action['speed']\n",
        "\n",
        "    if 'pick' in action.keys():\n",
        "      try:\n",
        "        self.pick(action['pick'], speed)\n",
        "      except NotImplementedError as e:\n",
        "        raise e\n",
        "\n",
        "    elif 'place' in action.keys():\n",
        "      try:\n",
        "        self.place(action['place'], speed)\n",
        "      except NotImplementedError as e:\n",
        "        raise e\n",
        "\n",
        "    elif 'push' in action.keys():\n",
        "      try:\n",
        "        self.push(action['push'], action['to'], speed)\n",
        "      except NotImplementedError as e:\n",
        "        raise e\n",
        "\n",
        "    observation = self.get_observation()\n",
        "    reward = self.get_reward()\n",
        "    done = False\n",
        "    info = {}\n",
        "    return observation, reward, done, info\n",
        "\n",
        "  def set_alpha_transparency(self, alpha: float) -> None:\n",
        "    for id in range(20):\n",
        "      visual_shape_data = pybullet.getVisualShapeData(id)\n",
        "      for i in range(len(visual_shape_data)):\n",
        "        object_id, link_index, _, _, _, _, _, rgba_color = visual_shape_data[i]\n",
        "        rgba_color = list(rgba_color[0:3]) +  [alpha]\n",
        "        pybullet.changeVisualShape(\n",
        "            self.robot_id, linkIndex=i, rgbaColor=rgba_color)\n",
        "        pybullet.changeVisualShape(\n",
        "            self.gripper.body, linkIndex=i, rgbaColor=rgba_color)\n",
        "\n",
        "  def step_sim_and_render(self):\n",
        "    pybullet.stepSimulation()\n",
        "    self.sim_step += 1\n",
        "\n",
        "    interval = 40 if self.high_frame_rate else 60\n",
        "    # Render current image at 8 FPS.\n",
        "    if self.sim_step % interval == 0 and self.render:\n",
        "      self.cache_video.append(self.get_camera_image())\n",
        "\n",
        "  def get_camera_image(self):\n",
        "    if not self.high_res:\n",
        "      image_size = (240, 240)\n",
        "      intrinsics = (120., 0, 120., 0, 120., 120., 0, 0, 1)\n",
        "    else:\n",
        "      image_size=(360, 360)\n",
        "      intrinsics=(180., 0, 180., 0, 180., 180., 0, 0, 1)\n",
        "    color, _, _, _, _ = self.render_image(image_size, intrinsics)\n",
        "    return color\n",
        "\n",
        "  def get_reward(self):\n",
        "    return None\n",
        "\n",
        "  def get_observation(self):\n",
        "    observation = {}\n",
        "\n",
        "    # Render current image.\n",
        "    color, depth, position, orientation, intrinsics = self.render_image()\n",
        "\n",
        "    # Get heightmaps and colormaps.\n",
        "    points = self.get_pointcloud(depth, intrinsics)\n",
        "    position = np.float32(position).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotation = np.float32(rotation).reshape(3, 3)\n",
        "    transform = np.eye(4)\n",
        "    transform[:3, :] = np.hstack((rotation, position))\n",
        "    points = self.transform_pointcloud(points, transform)\n",
        "    heightmap, colormap, xyzmap = self.get_heightmap(points, color, BOUNDS, PIXEL_SIZE)\n",
        "\n",
        "    observation[\"image\"] = colormap\n",
        "    observation[\"xyzmap\"] = xyzmap\n",
        "\n",
        "    return observation\n",
        "\n",
        "  def render_image(self, image_size=(720, 720), intrinsics=(360., 0, 360., 0, 360., 360., 0, 0, 1)):\n",
        "\n",
        "    # Camera parameters.\n",
        "    position = (0, -0.85, 0.4)\n",
        "    orientation = (np.pi / 4 + np.pi / 48, np.pi, np.pi)\n",
        "    orientation = pybullet.getQuaternionFromEuler(orientation)\n",
        "    zrange = (0.01, 10.)\n",
        "    noise=True\n",
        "\n",
        "    # OpenGL camera settings.\n",
        "    lookdir = np.float32([0, 0, 1]).reshape(3, 1)\n",
        "    updir = np.float32([0, -1, 0]).reshape(3, 1)\n",
        "    rotation = pybullet.getMatrixFromQuaternion(orientation)\n",
        "    rotm = np.float32(rotation).reshape(3, 3)\n",
        "    lookdir = (rotm @ lookdir).reshape(-1)\n",
        "    updir = (rotm @ updir).reshape(-1)\n",
        "    lookat = position + lookdir\n",
        "    focal_len = intrinsics[0]\n",
        "    znear, zfar = (0.01, 10.)\n",
        "    viewm = pybullet.computeViewMatrix(position, lookat, updir)\n",
        "    fovh = (image_size[0] / 2) / focal_len\n",
        "    fovh = 180 * np.arctan(fovh) * 2 / np.pi\n",
        "\n",
        "    # Notes: 1) FOV is vertical FOV 2) aspect must be float\n",
        "    aspect_ratio = image_size[1] / image_size[0]\n",
        "    projm = pybullet.computeProjectionMatrixFOV(fovh, aspect_ratio, znear, zfar)\n",
        "\n",
        "    # Render with OpenGL camera settings.\n",
        "    _, _, color, depth, segm = pybullet.getCameraImage(\n",
        "        width=image_size[1],\n",
        "        height=image_size[0],\n",
        "        viewMatrix=viewm,\n",
        "        projectionMatrix=projm,\n",
        "        shadow=1,\n",
        "        flags=pybullet.ER_SEGMENTATION_MASK_OBJECT_AND_LINKINDEX,\n",
        "        renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n",
        "\n",
        "    # Get color image.\n",
        "    color_image_size = (image_size[0], image_size[1], 4)\n",
        "    color = np.array(color, dtype=np.uint8).reshape(color_image_size)\n",
        "    color = color[:, :, :3]  # remove alpha channel\n",
        "    if noise:\n",
        "      color = np.int32(color)\n",
        "      color += np.int32(np.random.normal(0, 3, color.shape))\n",
        "      color = np.uint8(np.clip(color, 0, 255))\n",
        "\n",
        "    # Get depth image.\n",
        "    depth_image_size = (image_size[0], image_size[1])\n",
        "    zbuffer = np.float32(depth).reshape(depth_image_size)\n",
        "    depth = (zfar + znear - (2 * zbuffer - 1) * (zfar - znear))\n",
        "    depth = (2 * znear * zfar) / depth\n",
        "    if noise:\n",
        "      depth += np.random.normal(0, 0.003, depth.shape)\n",
        "\n",
        "    intrinsics = np.float32(intrinsics).reshape(3, 3)\n",
        "    return color, depth, position, orientation, intrinsics\n",
        "\n",
        "  def get_pointcloud(self, depth, intrinsics):\n",
        "    \"\"\"Get 3D pointcloud from perspective depth image.\n",
        "    Args:\n",
        "      depth: HxW float array of perspective depth in meters.\n",
        "      intrinsics: 3x3 float array of camera intrinsics matrix.\n",
        "    Returns:\n",
        "      points: HxWx3 float array of 3D points in camera coordinates.\n",
        "    \"\"\"\n",
        "    height, width = depth.shape\n",
        "    xlin = np.linspace(0, width - 1, width)\n",
        "    ylin = np.linspace(0, height - 1, height)\n",
        "    px, py = np.meshgrid(xlin, ylin)\n",
        "    px = (px - intrinsics[0, 2]) * (depth / intrinsics[0, 0])\n",
        "    py = (py - intrinsics[1, 2]) * (depth / intrinsics[1, 1])\n",
        "    points = np.float32([px, py, depth]).transpose(1, 2, 0)\n",
        "    return points\n",
        "\n",
        "  def transform_pointcloud(self, points, transform):\n",
        "    \"\"\"Apply rigid transformation to 3D pointcloud.\n",
        "    Args:\n",
        "      points: HxWx3 float array of 3D points in camera coordinates.\n",
        "      transform: 4x4 float array representing a rigid transformation matrix.\n",
        "    Returns:\n",
        "      points: HxWx3 float array of transformed 3D points.\n",
        "    \"\"\"\n",
        "    padding = ((0, 0), (0, 0), (0, 1))\n",
        "    homogen_points = np.pad(points.copy(), padding,\n",
        "                            'constant', constant_values=1)\n",
        "    for i in range(3):\n",
        "      points[Ellipsis, i] = np.sum(transform[i, :] * homogen_points, axis=-1)\n",
        "    return points\n",
        "\n",
        "  def get_heightmap(self, points, colors, bounds, pixel_size):\n",
        "    \"\"\"Get top-down (z-axis) orthographic heightmap image from 3D pointcloud.\n",
        "    Args:\n",
        "      points: HxWx3 float array of 3D points in world coordinates.\n",
        "      colors: HxWx3 uint8 array of values in range 0-255 aligned with points.\n",
        "      bounds: 3x2 float array of values (rows: X,Y,Z; columns: min,max) defining\n",
        "        region in 3D space to generate heightmap in world coordinates.\n",
        "      pixel_size: float defining size of each pixel in meters.\n",
        "    Returns:\n",
        "      heightmap: HxW float array of height (from lower z-bound) in meters.\n",
        "      colormap: HxWx3 uint8 array of backprojected color aligned with heightmap.\n",
        "      xyzmap: HxWx3 float array of XYZ points in world coordinates.\n",
        "    \"\"\"\n",
        "    width = int(np.round((bounds[0, 1] - bounds[0, 0]) / pixel_size))\n",
        "    height = int(np.round((bounds[1, 1] - bounds[1, 0]) / pixel_size))\n",
        "    heightmap = np.zeros((height, width), dtype=np.float32)\n",
        "    colormap = np.zeros((height, width, colors.shape[-1]), dtype=np.uint8)\n",
        "    xyzmap = np.zeros((height, width, 3), dtype=np.float32)\n",
        "\n",
        "    # Filter out 3D points that are outside of the predefined bounds.\n",
        "    ix = (points[Ellipsis, 0] >= bounds[0, 0]) & (points[Ellipsis, 0] < bounds[0, 1])\n",
        "    iy = (points[Ellipsis, 1] >= bounds[1, 0]) & (points[Ellipsis, 1] < bounds[1, 1])\n",
        "    iz = (points[Ellipsis, 2] >= bounds[2, 0]) & (points[Ellipsis, 2] < bounds[2, 1])\n",
        "    valid = ix & iy & iz\n",
        "    points = points[valid]\n",
        "    colors = colors[valid]\n",
        "\n",
        "    # Sort 3D points by z-value, which works with array assignment to simulate\n",
        "    # z-buffering for rendering the heightmap image.\n",
        "    iz = np.argsort(points[:, -1])\n",
        "    points, colors = points[iz], colors[iz]\n",
        "    px = np.int32(np.floor((points[:, 0] - bounds[0, 0]) / pixel_size))\n",
        "    py = np.int32(np.floor((points[:, 1] - bounds[1, 0]) / pixel_size))\n",
        "    px = np.clip(px, 0, width - 1)\n",
        "    py = np.clip(py, 0, height - 1)\n",
        "    heightmap[py, px] = points[:, 2] - bounds[2, 0]\n",
        "    for c in range(colors.shape[-1]):\n",
        "      colormap[py, px, c] = colors[:, c]\n",
        "      xyzmap[py, px, c] = points[:, c]\n",
        "    colormap = colormap[::-1, :, :]  # Flip up-down.\n",
        "    xv, yv = np.meshgrid(np.linspace(BOUNDS[0, 0], BOUNDS[0, 1], height),\n",
        "                         np.linspace(BOUNDS[1, 0], BOUNDS[1, 1], width))\n",
        "    xyzmap[:, :, 0] = xv\n",
        "    xyzmap[:, :, 1] = yv\n",
        "    xyzmap = xyzmap[::-1, :, :]  # Flip up-down.\n",
        "    heightmap = heightmap[::-1, :]  # Flip up-down.\n",
        "    return heightmap, colormap, xyzmap\n",
        "\n",
        "  def on_top_of(self, obj_a, obj_b):\n",
        "    \"\"\"\n",
        "    check if obj_a is on top of obj_b\n",
        "    condition 1: l2 distance on xy plane is less than a threshold\n",
        "    condition 2: obj_a is higher than obj_b\n",
        "    \"\"\"\n",
        "    obj_a_pos = self.get_obj_pos(obj_a)\n",
        "    obj_b_pos = self.get_obj_pos(obj_b)\n",
        "    xy_dist = np.linalg.norm(obj_a_pos[:2] - obj_b_pos[:2])\n",
        "    if obj_b in CORNER_POS:\n",
        "      is_near = xy_dist < 0.06\n",
        "      return is_near\n",
        "    elif 'bowl' in obj_b:\n",
        "      is_near = xy_dist < 0.06\n",
        "      is_higher = obj_a_pos[2] > obj_b_pos[2]\n",
        "      return is_near and is_higher\n",
        "    else:\n",
        "      is_near = xy_dist < 0.04\n",
        "      is_higher = obj_a_pos[2] > obj_b_pos[2]\n",
        "      return is_near and is_higher\n",
        "\n",
        "  def get_obj_id(self, obj_name):\n",
        "    # print(f'looking for {obj_name}')\n",
        "    try:\n",
        "      if obj_name in self.obj_name_to_id:\n",
        "        obj_id = self.obj_name_to_id[obj_name]\n",
        "      else:\n",
        "        obj_name = obj_name.replace('circle', 'bowl').replace('square', 'block').replace('small', '').strip()\n",
        "        obj_id = self.obj_name_to_id[obj_name]\n",
        "    except:\n",
        "      print(f'requested_name=\"{obj_name}\"')\n",
        "      print(f'available_objects_and_id=\"{self.obj_name_to_id}')\n",
        "    return obj_id\n",
        "\n",
        "  def get_obj_pos(self, obj_name):\n",
        "    obj_name = obj_name.replace('the', '').replace('_', ' ').strip()\n",
        "    if obj_name in CORNER_POS:\n",
        "      position = np.float32(np.array(CORNER_POS[obj_name]))\n",
        "    else:\n",
        "      pick_id = self.get_obj_id(obj_name)\n",
        "      pose = pybullet.getBasePositionAndOrientation(pick_id)\n",
        "      position = np.float32(pose[0])\n",
        "    return position\n",
        "\n",
        "  def get_bounding_box(self, obj_name):\n",
        "    obj_id = self.get_obj_id(obj_name)\n",
        "    return pybullet.getAABB(obj_id)\n",
        "\n",
        "  def save_video(self, path):\n",
        "    imageio.mimsave(path, self.cache_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcXqMMd-DhYx"
      },
      "source": [
        "# Wrapper & Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ldjDGSudDeEC"
      },
      "outputs": [],
      "source": [
        "class LMP_wrapper():\n",
        "\n",
        "  def __init__(self, env, cfg, render=False):\n",
        "    self.env = env\n",
        "    self._cfg = cfg\n",
        "    self.object_names = list(self._cfg['env']['init_objs'])\n",
        "\n",
        "    self._min_xy = np.array(self._cfg['env']['coords']['bottom_left'])\n",
        "    self._max_xy = np.array(self._cfg['env']['coords']['top_right'])\n",
        "    self._range_xy = self._max_xy - self._min_xy\n",
        "\n",
        "    self._table_z = self._cfg['env']['coords']['table_z']\n",
        "    self.render = render\n",
        "\n",
        "  def is_obj_visible(self, obj_name):\n",
        "    return obj_name in self.object_names\n",
        "\n",
        "  def get_obj_names(self):\n",
        "    return self.object_names[::]\n",
        "\n",
        "  def denormalize_xy(self, pos_normalized):\n",
        "    return pos_normalized * self._range_xy + self._min_xy\n",
        "\n",
        "  def get_corner_positions(self):\n",
        "    unit_square = box(0, 0, 1, 1)\n",
        "    normalized_corners = np.array(list(unit_square.exterior.coords))[:4]\n",
        "    corners = np.array(([self.denormalize_xy(corner) for corner in normalized_corners]))\n",
        "    return corners\n",
        "\n",
        "  def get_side_positions(self):\n",
        "    side_xs = np.array([0, 0.5, 0.5, 1])\n",
        "    side_ys = np.array([0.5, 0, 1, 0.5])\n",
        "    normalized_side_positions = np.c_[side_xs, side_ys]\n",
        "    side_positions = np.array(([self.denormalize_xy(corner) for corner in normalized_side_positions]))\n",
        "    return side_positions\n",
        "\n",
        "  def get_obj_pos(self, obj_name):\n",
        "    # return the xy position of the object in robot base frame\n",
        "    return self.env.get_obj_pos(obj_name)[:2]\n",
        "\n",
        "  def get_obj_position_np(self, obj_name):\n",
        "    return self.get_pos(obj_name)\n",
        "\n",
        "  def get_bbox(self, obj_name):\n",
        "    # return the axis-aligned object bounding box in robot base frame (not in pixels)\n",
        "    # the format is (min_x, min_y, max_x, max_y)\n",
        "    bbox = self.env.get_bounding_box(obj_name)\n",
        "    return bbox\n",
        "\n",
        "  def get_color(self, obj_name):\n",
        "    for color, rgb in COLORS.items():\n",
        "      if color in obj_name:\n",
        "        return rgb\n",
        "\n",
        "  # def pick_place(self, pick_pos, place_pos):\n",
        "  #   pick_pos_xyz = np.r_[pick_pos, [self._table_z]]\n",
        "  #   place_pos_xyz = np.r_[place_pos, [self._table_z]]\n",
        "  #   pass\n",
        "\n",
        "  # def put_first_on_second(self, arg1, arg2):\n",
        "  #   # put the object with obj_name on top of target\n",
        "  #   # target can either be another object name, or it can be an x-y position in robot base frame\n",
        "  #   # pick_pos = self.get_obj_pos(arg1) if isinstance(arg1, str) else arg1\n",
        "  #   # place_pos = self.get_obj_pos(arg2) if isinstance(arg2, str) else arg2\n",
        "  #   # self.env.step(action={'pick': pick_pos, 'place': place_pos})\n",
        "  #   self.env.step(action={'pick': arg1})\n",
        "  #   self.env.step(action={'place': arg2})\n",
        "\n",
        "  def pick(self, arg):\n",
        "    self.env.pick(arg)\n",
        "\n",
        "  def place(self, arg):\n",
        "    self.env.place(arg)\n",
        "\n",
        "  def push_obj_to(self, arg1, arg2):\n",
        "    self.env.push(arg1, arg2)\n",
        "\n",
        "  def get_robot_pos(self):\n",
        "    # return robot end-effector xy position in robot base frame\n",
        "    return self.env.get_ee_pos()\n",
        "\n",
        "  def goto_pos(self, position_xy):\n",
        "    # move the robot end-effector to the desired xy position while maintaining same z\n",
        "    ee_xyz = self.env.get_ee_pos()\n",
        "    position_xyz = np.concatenate([position_xy, ee_xyz[-1]])\n",
        "    while np.linalg.norm(position_xyz - ee_xyz) > 0.01:\n",
        "      self.env.movep(position_xyz)\n",
        "      self.env.step_sim_and_render()\n",
        "      ee_xyz = self.env.get_ee_pos()\n",
        "\n",
        "  def follow_traj(self, traj):\n",
        "    for pos in traj:\n",
        "      self.goto_pos(pos)\n",
        "\n",
        "  def get_corner_positions(self):\n",
        "    normalized_corners = np.array([\n",
        "        [0, 1],\n",
        "        [1, 1],\n",
        "        [0, 0],\n",
        "        [1, 0]\n",
        "    ])\n",
        "    return np.array(([self.denormalize_xy(corner) for corner in normalized_corners]))\n",
        "\n",
        "  def get_side_positions(self):\n",
        "    normalized_sides = np.array([\n",
        "        [0.5, 1],\n",
        "        [1, 0.5],\n",
        "        [0.5, 0],\n",
        "        [0, 0.5]\n",
        "    ])\n",
        "    return np.array(([self.denormalize_xy(side) for side in normalized_sides]))\n",
        "\n",
        "  def get_corner_name(self, pos):\n",
        "    corner_positions = self.get_corner_positions()\n",
        "    corner_idx = np.argmin(np.linalg.norm(corner_positions - pos, axis=1))\n",
        "    return ['top left corner', 'top right corner', 'bottom left corner', 'botom right corner'][corner_idx]\n",
        "\n",
        "  def get_side_name(self, pos):\n",
        "    side_positions = self.get_side_positions()\n",
        "    side_idx = np.argmin(np.linalg.norm(side_positions - pos, axis=1))\n",
        "    return ['top side', 'right side', 'bottom side', 'left side'][side_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RqYOOegpDldk"
      },
      "outputs": [],
      "source": [
        "class LMP_interface(LMP_wrapper):\n",
        "\n",
        "    def __init__(self, env, lmp_config, render=False):\n",
        "        super().__init__(env, lmp_config, render=render)\n",
        "        # self._cfg = lmp_config\n",
        "\n",
        "    def get_ee_pos(self):\n",
        "        return self.env.env.get_ee_pos()\n",
        "\n",
        "    def detect(self, obj_name, threshold=50):\n",
        "        if not self.is_obj_visible(obj_name):\n",
        "            return False\n",
        "        obj_id = self.env.get_obj_id(obj_name)\n",
        "        seg_image = self.env.env.get_seg_image()\n",
        "        # print(seg_image.shape)\n",
        "        height, width = seg_image.shape\n",
        "        obj_pixels = 0\n",
        "        for i in range(height):\n",
        "            for j in range(width):\n",
        "                # obj_id = seg_image[i][j]\n",
        "                if obj_id == seg_image[i][j]:\n",
        "                    obj_pixels += 1\n",
        "\n",
        "        return obj_pixels >= threshold\n",
        "\n",
        "    def reach(self, obj_name):\n",
        "        # if not self.detect(obj_name, threshold=50):\n",
        "        #     return False\n",
        "        target_pos = self.get_obj_pos(obj_name)\n",
        "        self.goto_pos(target_pos)\n",
        "\n",
        "        return self.env.is_close_to(obj_name, obj_name)\n",
        "\n",
        "    def pick(self, obj_name):\n",
        "        obj_pos = self.env.get_obj_pos_np(obj_name)\n",
        "        action = {\n",
        "            'pick': obj_pos,\n",
        "            }\n",
        "        self.env.step(action)\n",
        "\n",
        "        gripper_id = self.env.tip_link_id\n",
        "        obj_id = self.env.get_obj_id(obj_name)\n",
        "        is_holding = False\n",
        "        gripper_link_ids = self.env.gripper.body\n",
        "        contacts = pybullet.getContactPoints(gripper_id, obj_id)\n",
        "        for contact in contacts:\n",
        "            if contact[3] in gripper_link_ids:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def place(self, obj_name, dest_name):\n",
        "        if not self.is_obj_visible(obj_name):\n",
        "            return False # Unknown object\n",
        "        if not dest_name in CORNER_POS and not self.is_obj_visible(dest_name):\n",
        "            return False # Unknown destination\n",
        "\n",
        "        # Check whether obj is already being held\n",
        "        obj_id = self.get_obj_id(obj_name)\n",
        "        gripper_id = self.env.tip_link_id\n",
        "        gripper_link_ids = self.env.gripper.body\n",
        "        contacts = pybullet.getContactPoints(gripper_id, obj_id)\n",
        "        is_holding = False\n",
        "        for c in contacts:\n",
        "            if c[3] in gripper_link_ids:\n",
        "                is_holding = True\n",
        "        if not is_holding:\n",
        "            return False # Pick up the object first\n",
        "\n",
        "        if dest_name in CORNER_POS.keys():\n",
        "            to_pos = CORNER_POS[dest_name]\n",
        "        else:\n",
        "            to_pos = self.get_obj_pos_np(dest_name)\n",
        "\n",
        "        action = {\n",
        "            'place': obj_pos,\n",
        "        }\n",
        "        self.env.step(action)\n",
        "\n",
        "        if not dest_name in CORNER_POS.keys():\n",
        "            return self.is_close_to(obj_name, dest_name)\n",
        "        else:\n",
        "            obj_pos = self.get_obj_pos_np(obj_name)\n",
        "            return np.linalg.norm(obj_pos-to_pos) < 0.1\n",
        "\n",
        "    # def pick_and_place(self, obj_name, pos_name):\n",
        "    #     raise NotImplementedError # Use pick and place seperately\n",
        "\n",
        "    def push(self, obj_name, dest_name):\n",
        "\n",
        "        if not self.is_obj_visible(obj_name):\n",
        "            return False # Unknown object\n",
        "\n",
        "        if not dest_name in CORNER_POS and not self.is_obj_visible(dest_name):\n",
        "            return False # Unknown destination\n",
        "\n",
        "        push_pos = self.get_obj_pos_np(obj_name)\n",
        "        if dest_name in CORNER_POS.keys():\n",
        "            to_pos = CORNER_POS[dest_name]\n",
        "        else:\n",
        "            to_pos = self.get_obj_pos_np(dest_name)\n",
        "        action = {\n",
        "            'push': obj_name,\n",
        "            'to': to_pos\n",
        "        }\n",
        "\n",
        "        self.env.step(action)\n",
        "\n",
        "        if not dest_name in CORNER_POS.keys():\n",
        "            return self.is_close_to(obj_name, dest_name)\n",
        "        else:\n",
        "            obj_pos = self.get_obj_pos_np(obj_name)\n",
        "            return np.linalg.norm(obj_pos-to_pos) < 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9R11_QGDorG",
        "outputId": "0f52d8c4-e27b-4278-c6b3-5ecc011e8b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘prompts/’: File exists\n",
            "mkdir: cannot create directory ‘videos/’: File exists\n",
            "mv: cannot stat '*.txt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir prompts/\n",
        "!mkdir videos/\n",
        "!mv *.txt prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm5Go_8kD041"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uOe9IB88DwyR"
      },
      "outputs": [],
      "source": [
        "def build_cfg(keys, prompts):\n",
        "  assert len(keys) == len(prompts)\n",
        "  cfg = {}\n",
        "  tabletop_cfg = {}\n",
        "  for i, k in enumerate(keys):\n",
        "    # print(k, i)\n",
        "    with open('prompts/{}.txt'.format(prompts[i]), 'r') as f:\n",
        "      prompt = f.read().strip()\n",
        "    cfg[k] = {\n",
        "      'prompt_text': prompt,\n",
        "      'engine': model_name,\n",
        "      'max_tokens': 512,\n",
        "      'temperature': 0,\n",
        "      'query_prefix': '# ',\n",
        "      'query_suffix': '.',\n",
        "      'stop': ['#'],\n",
        "      'maintain_session': False,\n",
        "      'debug_mode': False,\n",
        "      'include_context': True,\n",
        "      'has_return': True,\n",
        "      'return_val_name': 'new_shape_pts',\n",
        "    }\n",
        "  tabletop_cfg['lmps'] = cfg\n",
        "  return tabletop_cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s_ou3jUEA9S"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SWXyimyqEGt9"
      },
      "outputs": [],
      "source": [
        "#@title Initialize Env { vertical-output: true }\n",
        "num_blocks = 2 #@param {type:\"slider\", min:0, max:4, step:1}\n",
        "num_bowls = 1 #@param {type:\"slider\", min:0, max:4, step:1}\n",
        "high_resolution = False #@param {type:\"boolean\"}\n",
        "high_frame_rate = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKddzYe6FVwL"
      },
      "outputs": [],
      "source": [
        "env = GeneralEnv(render=True, high_res=high_resolution, high_frame_rate=high_frame_rate, test=False)\n",
        "# block_list = np.random.choice(ALL_BLOCKS, size=num_blocks, replace=False).tolist()\n",
        "# bowl_list = np.random.choice(ALL_BOWLS, size=num_bowls, replace=False).tolist()\n",
        "\n",
        "block_list = ['blue block', 'red block']\n",
        "bowl_list = ['blue bowl']\n",
        "\n",
        "pickable_cfg = {\n",
        "    'blue block': False,\n",
        "    'red block': True,\n",
        "    'blue bowl': True\n",
        "}\n",
        "\n",
        "obj_list = block_list + bowl_list\n",
        "_ = env.reset(obj_list, pickable_cfg)\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "# act = {'pick': obj_list[0]}\n",
        "# env.step(act)\n",
        "# act = {'place': obj_list[1]}\n",
        "# env.step(act)\n",
        "\n",
        "user_input = 'get the blue block into the blue bowl' #\n",
        "\n",
        "env.cache_video = []\n",
        "\n",
        "keys = ['fgen', 'parse_obj_name', 'parse_position', 'parse_question', 'table_ui', 'transform_shape_pts']\n",
        "prompts = keys\n",
        "cfg_tabletop = build_cfg(keys, prompts)\n",
        "lmp_tabletop_ui = setup_LMP(env, cfg_tabletop)\n",
        "lmp_tabletop_ui(user_input, f'objects = {env.object_list}')\n",
        "\n",
        "env.save_video('videos/test_lmp_push.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw_jH1DH-O8t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SPMS8UWXBym6",
        "QbESO6mwDIEO",
        "pWu8o61yDKDP",
        "QcXqMMd-DhYx",
        "Wm5Go_8kD041",
        "0s_ou3jUEA9S"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
